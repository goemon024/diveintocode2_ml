{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sprint19 セグメンテーション２"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   【問題1】コードレビュー  \n",
    "<総括>　前回のモデル（git上のUnet）は、seaquential モデルでコンパイルされて構築されている。構築されたunetに対して、データが入力されると、セグメンテーションされたデータが出力される。  \n",
    "　  \n",
    "　今回のモデル（下記のUnet）は、ベースモデルとして前段にkerasのRESNET50が採用されて、後段には「decorder block（bottle_neck）」が採用される。  \n",
    "　  \n",
    "　転移学習となる今回のtrainingでは、Resnetの初期値（imagenetのデータセットで学習されたもの）が利用されて学習が効率化されている（学習により、前段、後段ともにパラメータが更新される（∵trainable））。  \n",
    "　  \n",
    "　なお前回とは異なり、predictやtrainingでは、Kfoldによってtrainとvalidationデータに分割されたものが用いられる。（threshold optimizationやiouなどについては、前回は定義されておらず不明）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  【問題2】コードの書き換え  \n",
    "　書き換え箇所を###★★★###　で示す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\hirot\\anaconda3\\lib\\site-packages (4.2.0.32)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\hirot\\anaconda3\\lib\\site-packages (from opencv-python) (1.16.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T07:08:26.011539Z",
     "start_time": "2019-09-25T07:08:20.644512Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "#from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "### ★★★ ###\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "### ★★★ ###\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/sample_submission.csv')\n",
    "depth = pd.read_csv('input/depths.csv')\n",
    "\n",
    "train_src = '../input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 17,  17,  17],\n",
       "        [ 20,  20,  20],\n",
       "        [ 23,  23,  23],\n",
       "        ...,\n",
       "        [ 92,  92,  92],\n",
       "        [ 81,  81,  81],\n",
       "        [ 73,  73,  73]],\n",
       "\n",
       "       [[ 26,  26,  26],\n",
       "        [ 26,  26,  26],\n",
       "        [ 26,  26,  26],\n",
       "        ...,\n",
       "        [ 81,  81,  81],\n",
       "        [ 72,  72,  72],\n",
       "        [ 65,  65,  65]],\n",
       "\n",
       "       [[ 48,  48,  48],\n",
       "        [ 44,  44,  44],\n",
       "        [ 42,  42,  42],\n",
       "        ...,\n",
       "        [ 73,  73,  73],\n",
       "        [ 65,  65,  65],\n",
       "        [ 62,  62,  62]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[143, 143, 143],\n",
       "        [147, 147, 147],\n",
       "        [151, 151, 151],\n",
       "        ...,\n",
       "        [165, 165, 165],\n",
       "        [167, 167, 167],\n",
       "        [170, 170, 170]],\n",
       "\n",
       "       [[178, 178, 178],\n",
       "        [181, 181, 181],\n",
       "        [184, 184, 184],\n",
       "        ...,\n",
       "        [168, 168, 168],\n",
       "        [171, 171, 171],\n",
       "        [174, 174, 174]],\n",
       "\n",
       "       [[209, 209, 209],\n",
       "        [211, 211, 211],\n",
       "        [213, 213, 213],\n",
       "        ...,\n",
       "        [174, 174, 174],\n",
       "        [177, 177, 177],\n",
       "        [179, 179, 179]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(cv2.imread(\"input/train/images/{}.png\".format(\"4875705fb0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('input/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('input/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a51bceda08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_function(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_function(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜メモ＞  \n",
    "AttributeError: module 'tensorflow' has no attribute 'py_func'のエラーのため、   \n",
    "py_func →　py_functionに修正。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T07:09:31.695684Z",
     "start_time": "2019-09-25T07:09:24.147636Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "## include_top = False 分類気のところは使わない。畳み込みのところだけを使う。\n",
    "### ★★★ ###\n",
    "base_model = VGG16(input_shape=input_size, include_top=False)\n",
    "### ★★★ ###\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "# keras.applications.vgg16.VGG16(include_top=False,input_shape=input_size)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・include_top:畳み込み層のあとにある3つの全結合層を利用するか決める。\n",
    "・weights:重みの値を決める。\n",
    "　　　　　None : ランダム初期化\n",
    "　　　　　'imagenet' : ImageNet学習済みパラメータ\n",
    "　　　　　パラメータ保存ファイルのパスも指定可能\n",
    "・input_tensor:モデルの入力に利用するkerasのTensor\n",
    "・input_shape:入力のサイズを決める\n",
    "・pooling:最終畳み込み出力の処理を決める(include_topがFalseのとき)\n",
    "　　　　　None：そのままの値\n",
    "　　　　　max：global max pooling\n",
    "　　　　　avg：global average pooling\n",
    "・classes:出力のクラス数を決める(include_topがTrueのとき)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "\n",
    "# weightsは、imagenetのデータセットで学習されたものであるという意味。\n",
    "\n",
    "def unet_vgg16(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "\n",
    "###  Resnet50の場合　###    \n",
    "#     encoder1 = base_model.get_layer('activation_1').output\n",
    "#     encoder2 = base_model.get_layer('activation_10').output\n",
    "#     encoder3 = base_model.get_layer('activation_22').output\n",
    "#     encoder4 = base_model.get_layer('activation_40').output\n",
    "#     encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "\n",
    "###  vgg16の場合：こちらは出力のshapeが合わない　###    \n",
    "#     encoder1 = base_model.get_layer('block1_conv2').output\n",
    "#     encoder2 = base_model.get_layer('block2_conv2').output\n",
    "#     encoder3 = base_model.get_layer('block3_conv3').output\n",
    "#     encoder4 = base_model.get_layer('block4_conv3').output\n",
    "#     encoder5 = base_model.get_layer('block5_conv3').output\n",
    "\n",
    "###  vgg16の場合　###      \n",
    "    encoder1 = base_model.get_layer('block1_pool').output\n",
    "    encoder2 = base_model.get_layer('block2_pool').output\n",
    "    encoder3 = base_model.get_layer('block3_pool').output\n",
    "    encoder4 = base_model.get_layer('block4_pool').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,611,201\n",
      "Trainable params: 22,609,089\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg16(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,677,489\n",
      "Trainable params: 28,672,209\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " InvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a bool tensor [Op:Mul] name: mul/\nTraceback (most recent call last):\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 234, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 123, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-11-b6c7ada06edd>\", line 138, in get_iou_vector\n    intersection = np.sum(t * p)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\", line 902, in binary_op_wrapper\n    return func(x, y, name=name)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\", line 1201, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 6121, in mul\n    _ops.raise_from_not_ok_status(e, name)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 6606, in raise_from_not_ok_status\n    six.raise_from(core._status_to_exception(e.code, message), None)\n\n  File \"<string>\", line 3, in raise_from\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a bool tensor [Op:Mul] name: mul/\n\n\n\t [[node metrics/my_iou_metric/EagerPyFunc (defined at C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_25792]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-34b68b14826d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                     verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  InvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a bool tensor [Op:Mul] name: mul/\nTraceback (most recent call last):\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 234, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 123, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-11-b6c7ada06edd>\", line 138, in get_iou_vector\n    intersection = np.sum(t * p)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\", line 902, in binary_op_wrapper\n    return func(x, y, name=name)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\", line 1201, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 6121, in mul\n    _ops.raise_from_not_ok_status(e, name)\n\n  File \"C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 6606, in raise_from_not_ok_status\n    six.raise_from(core._status_to_exception(e.code, message), None)\n\n  File \"<string>\", line 3, in raise_from\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a bool tensor [Op:Mul] name: mul/\n\n\n\t [[node metrics/my_iou_metric/EagerPyFunc (defined at C:\\Users\\hirot\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_25792]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg16(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "\n",
    "\n",
    "#decoder_block,\n",
    "#loss_func='binary_crossentropy',\n",
    "\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asarrayは同期コピー(arrayは同期しないコピー)。\n",
    "\n",
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/35 [00:00<?, ?it/s]\n",
      "  3%|██▎                                                                                | 1/35 [00:02<01:27,  2.58s/it]\n",
      "  6%|████▋                                                                              | 2/35 [00:04<01:23,  2.53s/it]\n",
      "  9%|███████                                                                            | 3/35 [00:07<01:19,  2.49s/it]\n",
      " 11%|█████████▍                                                                         | 4/35 [00:09<01:13,  2.36s/it]\n",
      " 14%|███████████▊                                                                       | 5/35 [00:11<01:11,  2.37s/it]\n",
      " 17%|██████████████▏                                                                    | 6/35 [00:14<01:13,  2.55s/it]\n",
      " 20%|████████████████▌                                                                  | 7/35 [00:17<01:13,  2.63s/it]\n",
      " 23%|██████████████████▉                                                                | 8/35 [00:20<01:13,  2.72s/it]\n",
      " 26%|█████████████████████▎                                                             | 9/35 [00:23<01:11,  2.76s/it]\n",
      " 29%|███████████████████████▍                                                          | 10/35 [00:25<01:06,  2.67s/it]\n",
      " 31%|█████████████████████████▊                                                        | 11/35 [00:28<01:01,  2.56s/it]\n",
      " 34%|████████████████████████████                                                      | 12/35 [00:30<01:00,  2.62s/it]\n",
      " 37%|██████████████████████████████▍                                                   | 13/35 [00:33<00:54,  2.49s/it]\n",
      " 40%|████████████████████████████████▊                                                 | 14/35 [00:35<00:51,  2.46s/it]\n",
      " 43%|███████████████████████████████████▏                                              | 15/35 [00:37<00:47,  2.39s/it]\n",
      " 46%|█████████████████████████████████████▍                                            | 16/35 [00:40<00:48,  2.56s/it]\n",
      " 49%|███████████████████████████████████████▊                                          | 17/35 [00:43<00:47,  2.66s/it]\n",
      " 51%|██████████████████████████████████████████▏                                       | 18/35 [00:46<00:46,  2.76s/it]\n",
      " 54%|████████████████████████████████████████████▌                                     | 19/35 [00:49<00:44,  2.81s/it]\n",
      " 57%|██████████████████████████████████████████████▊                                   | 20/35 [00:52<00:43,  2.90s/it]\n",
      " 60%|█████████████████████████████████████████████████▏                                | 21/35 [00:55<00:40,  2.91s/it]\n",
      " 63%|███████████████████████████████████████████████████▌                              | 22/35 [00:58<00:38,  2.93s/it]\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 23/35 [01:01<00:35,  2.98s/it]\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 24/35 [01:04<00:33,  3.01s/it]\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [01:07<00:28,  2.83s/it]\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [01:10<00:25,  2.85s/it]\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [01:12<00:22,  2.77s/it]\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [01:15<00:19,  2.77s/it]\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [01:18<00:16,  2.75s/it]\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [01:20<00:13,  2.77s/it]\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 31/35 [01:23<00:11,  2.78s/it]\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 32/35 [01:26<00:08,  2.84s/it]\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 33/35 [01:28<00:05,  2.67s/it]\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 34/35 [01:31<00:02,  2.76s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [01:34<00:00,  2.71s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.4194 at threshold: 0.200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.136869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.151425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.002861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.060075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.271144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.419403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.136869\n",
       "std     0.204939   0.151425\n",
       "min     0.200000   0.000000\n",
       "25%     0.370000   0.002861\n",
       "50%     0.540000   0.060075\n",
       "75%     0.710000   0.271144\n",
       "max     0.880000   0.419403"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a5b6f996c8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＜ＲＥＳＮＥＴとの比較＞  \n",
    "　ＲＥＳＮＥＴのほうがＩＯＵにおいて優れた結果となった（thresholdの広い範囲でｒｅｓｎｅｔのＩＯＵが高い）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:26:39.786782Z",
     "start_time": "2019-09-25T08:26:39.781446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Keras - Clean Project WorkflowでのUnetについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depthがゼロになるまで、関数level_blockが再帰的に呼び出される。  \n",
    "up=True,depth>0のとき、関数lebel_blockの１回の呼び出しにより、  \n",
    "UNETの前段側のネットワークである１対のconv_blodkとMax_pooling2D()によるネットワークと、  \n",
    "UNETの後段側のネットワークである１対のUpsamplingとConv2Dによるネットワークが構築される。  \n",
    "そして、前段側のconv_blockからの出力（ｎ）と、後段からのconv2Dからの出力（ｍ）がconcatenateされる。  \n",
    "　  \n",
    "depthが0に近づくにつしたがってUnetの深い段階のネットワークに対応し、  \n",
    "Unetの最深部（depth=0）では、conv_blockによる出力が関数lebel_blockの出力となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,\n",
    "                          Conv2DTranspose, Dropout, Input, MaxPooling2D,\n",
    "                          UpSampling2D, concatenate)\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def conv_block(m, dim, acti, bn, res, do=0):\n",
    "    n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
    "    n = BatchNormalization()(n) if bn else n\n",
    "    n = Dropout(do)(n) if do else n\n",
    "    n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
    "    n = BatchNormalization()(n) if bn else n\n",
    "    return Concatenate()([m, n]) if res else n\n",
    "\n",
    "def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
    "    if depth > 0:\n",
    "        n = conv_block(m, dim, acti, bn, res)\n",
    "        m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
    "        m = level_block(m, int(inc * dim), depth - 1,\n",
    "                        inc, acti, do, bn, mp, up, res)\n",
    "        if up:\n",
    "            m = UpSampling2D()(m)\n",
    "            m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
    "        else:\n",
    "            m = Conv2DTranspose(dim, 3, strides=2,\n",
    "                                activation=acti, padding='same')(m)\n",
    "        n = Concatenate()([n, m])\n",
    "        m = conv_block(n, dim, acti, bn, res)\n",
    "    else:\n",
    "        m = conv_block(m, dim, acti, bn, res, do)\n",
    "    return m\n",
    "\n",
    "\n",
    "def UNet(params):\n",
    "\n",
    "    img_shape = params['input_dim']\n",
    "    out_ch = 1\n",
    "    start_ch = 8\n",
    "    depth = 3\n",
    "    inc_rate = 2.\n",
    "    activation = 'relu'\n",
    "    dropout = 0.5\n",
    "    batchnorm = False\n",
    "    maxpool = True\n",
    "    upconv = True\n",
    "    residual = False\n",
    "\n",
    "    i = Input(shape=img_shape)\n",
    "    o = level_block(i, start_ch, depth, inc_rate, activation,\n",
    "                    dropout, batchnorm, maxpool, upconv, residual)\n",
    "    o = Conv2D(out_ch, 1)(o)\n",
    "    # Sigmoid activation is used because model is trained with binary_crossentropy.\n",
    "    o =  Activation('sigmoid')(o)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o)\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

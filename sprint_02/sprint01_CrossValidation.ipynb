{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint クロスバリデーション　スクラッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】クロスバリデーション\n",
    "\n",
    "事前学習期間では検証用データをはじめに分割しておき、それに対して指標値を計算することで検証を行っていました。（ホールドアウト法）しかし、分割の仕方により精度は変化します。実践的には クロスバリデーション（交差検証） を行います。分割を複数回行い、それぞれに対して学習と検証を行う方法です。複数回の分割のためにscikit-learnにはKFoldクラスが用意されています。\n",
    "\n",
    "事前学習期間の課題で作成したベースラインモデルに対してKFoldクラスによるクロスバリデーションを行うコードを作成し実行してください。\n",
    "\n",
    "sklearn.model_selection.KFold — scikit-learn 0.21.3 documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('application_train.csv')#教師データを読み込む\n",
    "\n",
    "pd.set_option('display.max_columns', 250)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "#application_test = pd.read_csv(\"application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objectの欠損値をmodeで、int,floatの欠損値をmeanで置換。mode()後の[0]に注意。\n",
    "df_object = df.select_dtypes(include = \"object\")\n",
    "for column in df_object.columns:\n",
    "    df[column] = df_object[column].fillna(df_object[column].mode()[0])\n",
    "df_int_float = df.select_dtypes(exclude = \"object\")\n",
    "for column in df_int_float.columns:\n",
    "    df[column] = df_int_float[column].fillna(df_int_float[column].mean())\n",
    "    \n",
    "# 欠損値が全て穴埋めされた確認。\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 122)\n",
      "(307511, 262)\n",
      "(307511, 246)\n"
     ]
    }
   ],
   "source": [
    "### ダミー処理 ###\n",
    "print(df.shape)\n",
    "df_onehot = df\n",
    "for column in df_object.columns:\n",
    "    df_onehot = pd.concat([df_onehot, pd.get_dummies(df[column])],axis=1)\n",
    "\n",
    "print(df_onehot.shape)\n",
    "for column in df_object.columns:\n",
    "    df_onehot = df_onehot.drop(column, axis=1)\n",
    "\n",
    "print(df_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "###　特徴量選択　###\n",
    "df_onehot=df_onehot[['LIVINGAREA_MODE', 'Secondary / secondary special',\n",
    "       'YEARS_BEGINEXPLUATATION_MODE', 'COMMONAREA_MODE', 'TOTALAREA_MODE',\n",
    "       'M', 'OWN_CAR_AGE', 'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "       'HOUR_APPR_PROCESS_START', 'AMT_GOODS_PRICE', 'AMT_CREDIT',\n",
    "       'REGION_POPULATION_RELATIVE', 'AMT_INCOME_TOTAL',\n",
    "       'DAYS_LAST_PHONE_CHANGE', 'DAYS_EMPLOYED', 'AMT_ANNUITY',\n",
    "       'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'DAYS_BIRTH', 'EXT_SOURCE_1',\n",
    "       'EXT_SOURCE_2', 'EXT_SOURCE_3']]\n",
    "\n",
    "#        'Married', 'NONLIVINGAREA_MEDI', 'TUESDAY',\n",
    "#        'CNT_CHILDREN', 'NONLIVINGAREA_MODE', 'LANDAREA_AVG', 'LANDAREA_MODE',\n",
    "#        'LANDAREA_MEDI', 'OBS_60_CNT_SOCIAL_CIRCLE', 'LIVINGAPARTMENTS_MODE',\n",
    "#        'DEF_30_CNT_SOCIAL_CIRCLE', 'YEARS_BEGINEXPLUATATION_MEDI',\n",
    "#        'YEARS_BEGINEXPLUATATION_AVG', 'FLAG_DOCUMENT_3',\n",
    "#        'LIVINGAPARTMENTS_AVG', 'CNT_FAM_MEMBERS', 'LIVINGAREA_MEDI',\n",
    "#        'OBS_30_CNT_SOCIAL_CIRCLE', 'YEARS_BUILD_MEDI', 'LIVINGAREA_AVG',\n",
    "#        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAPARTMENTS_MEDI',\n",
    "#        'REG_CITY_NOT_LIVE_CITY', 'Managers', 'ENTRANCES_MODE',\n",
    "#        'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "#        'REGION_RATING_CLIENT', 'AMT_REQ_CREDIT_BUREAU_MON', 'THURSDAY',\n",
    "#        'ENTRANCES_AVG', 'BASEMENTAREA_MODE', 'Higher education', 'Working',\n",
    "#        'Commercial associate', 'F', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG',\n",
    "#        'FLOORSMAX_MODE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'ENTRANCES_MEDI',\n",
    "#        'APARTMENTS_MODE',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 特徴量の追加 ###\n",
    "df_onehot[\"CREDIT/INCOME\"] = df_onehot[\"AMT_CREDIT\"]/df_onehot[\"AMT_INCOME_TOTAL\"]\n",
    "df_onehot[\"CREDIT/GOODS\"] = df_onehot[\"AMT_CREDIT\"]/df_onehot[\"AMT_GOODS_PRICE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91798774 0.91793763 0.91901076 0.91601899 0.91954733]\n",
      "0.918100491080809\n"
     ]
    }
   ],
   "source": [
    "## cross validation\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "X = df_onehot.values\n",
    "y = df.TARGET.values\n",
    "\n",
    "clf = RandomForestClassifier(random_state = 30 )\n",
    "kf = KFold(n_splits=5, random_state= 1, shuffle=True)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=kf, n_jobs = -1)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91782515 0.91816526 0.91748236 0.91797015 0.91785633]\n",
      "0.9178598490288227\n"
     ]
    }
   ],
   "source": [
    "##　stratified kfoldのcross validation\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "scores = cross_val_score(clf, X, y, cv=skf, n_jobs = -1)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64388682 0.64974486 0.64855141 0.646142   0.65127444]\n",
      "0.6479199055125682\n"
     ]
    }
   ],
   "source": [
    "##　stratified kfoldのcross validation (roc_auc)\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "scores = cross_val_score(clf, X, y, cv=skf, n_jobs = -1, scoring = \"roc_auc\")\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】グリッドサーチ\n",
    "\n",
    "　これまで分類器のパラメータには触れず、デフォルトの設定を使用していました。パラメータの詳細は今後のSprintで学んでいくことになります。機械学習の前提として、パラメータは状況に応じて最適なものを選ぶ必要があります。最適なパラメータを探していくことを パラメータチューニング と呼びます。パラメータチューニングをある程度自動化する単純な方法としては グリッドサーチ があります。  \n",
    "　  \n",
    "scikit-learnのGridSearchCVを使い、グリッドサーチを行うコードを作成してください。そして、ベースラインモデルに対して何らかしらのパラメータチューニングを行なってください。どのパラメータをチューニングするかは、使用した手法の公式ドキュメントを参考にしてください。  \n",
    "　  \n",
    "sklearn.model_selection.GridSearchCV — scikit-learn 0.21.3 documentation　  \n",
    "　  \n",
    "GridSearchCVクラスには引数としてモデル、探索範囲、さらにクロスバリデーションを何分割で行うかを与えます。クロスバリデーションの機能も含まれているため、これを使用する場合はKFoldクラスを利用する必要はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7436332745122856\n",
      "{'max_depth': 10, 'n_estimators': 70}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>72.799371</td>\n",
       "      <td>9.795673</td>\n",
       "      <td>0.855188</td>\n",
       "      <td>0.239744</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 70}</td>\n",
       "      <td>0.743285</td>\n",
       "      <td>0.744097</td>\n",
       "      <td>0.739750</td>\n",
       "      <td>0.745442</td>\n",
       "      <td>0.745592</td>\n",
       "      <td>0.743633</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>132.309159</td>\n",
       "      <td>5.073169</td>\n",
       "      <td>1.830294</td>\n",
       "      <td>0.498631</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 70}</td>\n",
       "      <td>0.727933</td>\n",
       "      <td>0.728724</td>\n",
       "      <td>0.722636</td>\n",
       "      <td>0.728795</td>\n",
       "      <td>0.726022</td>\n",
       "      <td>0.726822</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>129.590586</td>\n",
       "      <td>12.245406</td>\n",
       "      <td>1.965022</td>\n",
       "      <td>0.685651</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 70}</td>\n",
       "      <td>0.715498</td>\n",
       "      <td>0.714975</td>\n",
       "      <td>0.709829</td>\n",
       "      <td>0.712103</td>\n",
       "      <td>0.712340</td>\n",
       "      <td>0.712949</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      72.799371      9.795673         0.855188        0.239744   \n",
       "1     132.309159      5.073169         1.830294        0.498631   \n",
       "2     129.590586     12.245406         1.965022        0.685651   \n",
       "\n",
       "  param_max_depth param_n_estimators                                 params  \\\n",
       "0              10                 70  {'max_depth': 10, 'n_estimators': 70}   \n",
       "1              20                 70  {'max_depth': 20, 'n_estimators': 70}   \n",
       "2              30                 70  {'max_depth': 30, 'n_estimators': 70}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.743285           0.744097           0.739750           0.745442   \n",
       "1           0.727933           0.728724           0.722636           0.728795   \n",
       "2           0.715498           0.714975           0.709829           0.712103   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.745592         0.743633        0.002122                1  \n",
       "1           0.726022         0.726822        0.002320                2  \n",
       "2           0.712340         0.712949        0.002070                3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_estimators':[70],\n",
    "          \"max_depth\": [10, 20, 30]       \n",
    "         }\n",
    "    \n",
    "#    'max_depth': list(range(4, 10)),\n",
    "#    'min_samples_split': [2,4,6],\n",
    "#    'criterion': ['gini', 'entropy'],\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(clf,  # 分類器を渡す\n",
    "                           param_grid=params,  # 試行してほしいパラメータを渡す\n",
    "                           cv=5,  # 5-Fold CV で汎化性能を調べる\n",
    "                           scoring = \"roc_auc\"\n",
    "                           )\n",
    "\n",
    "# グリッドサーチで優れたハイパーパラメータを探す\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(grid_search.best_score_)  # 最も良かったスコア\n",
    "print(grid_search.best_params_)  # 上記を記録したパラメータの組み合わせ\n",
    "\n",
    "display(pd.DataFrame(grid_search.cv_results_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算時間がかかるので、n_estimators は個別に実行した（他の変数は一定）。  \n",
    "n_estimators = 30 では、roc_aucが0.6897となり、  \n",
    "n_estimators = 50～100では、roc_aucが0.71となった。  \n",
    "（n_estimators = 75、100では、roc_aucが0.7115、0.7158だった）。  \n",
    "したがって、グリッドサーチにより、{'max_depth': 10, 'n_estimators': 70}とする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】Kernelからの調査\n",
    "\n",
    "・LightGBMによる計算が良いようだ。特徴量を増やしても計算速度が致命的な副作用は少ないようだが、無差別に採用するのはよくないようだ。  \n",
    "<br>\n",
    "・ハイパーパラメータの調整よりも特徴量エンジニアリングを重視すべきのようだ。特徴量エンジニアリングでは、カラム同士の演算、min,max,mean,var,countなどを用いた集計は多くの方がやっており、ターゲットエンコーディングなども有望そうだ。  \n",
    "<br>\n",
    "・クロスバリデーションによる汎化性能は、コンペにおいては極めて重要であるということだ。モデルの乱数seedを変えるとスコアが結構変わることもあるらしく、ひとまずStratifiedKFold(k=5)を用いている。  \n",
    "　  \n",
    "・StratifiedKFold(層化抽出法）を使うと、サブセットを作るときに目的変数の比率がなるべく元のままになるように分割できる。  \n",
    "<br>\n",
    "・今回のデータには、時系列性が内包されているらしくクロスバリデーションのスコアとＬＢのスコアがぶれてしまうという問題があるようだ。（時系列性を取り除くのは、application_csv以外のファイルの検証をする必要がありそうだ）。なお１位のカーネルでは、時系列性に着目したラグ特徴量を使用しているようだ。  \n",
    "<br>\n",
    "・特徴量を新しく作成する時には、クロスバリデーションの際の計算速度を向上させて早く回す必要があるため、新たな特徴料以外の特徴量を少なめに選別して試行錯誤すると良い。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】高い汎化性能のモデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ＬＧＢＭとstratifiedkfoldを使ってみる。特徴量エンジニアリングは既にある程度は実行しているので、ハイパーパラメータの検討を行ってみる。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.256476\tvalid_1's binary_logloss: 0.256656\n",
      "[20]\ttraining's binary_logloss: 0.249864\tvalid_1's binary_logloss: 0.250693\n",
      "[30]\ttraining's binary_logloss: 0.246534\tvalid_1's binary_logloss: 0.248259\n",
      "[40]\ttraining's binary_logloss: 0.244372\tvalid_1's binary_logloss: 0.247108\n",
      "[50]\ttraining's binary_logloss: 0.242589\tvalid_1's binary_logloss: 0.246297\n",
      "[60]\ttraining's binary_logloss: 0.241074\tvalid_1's binary_logloss: 0.245795\n",
      "[70]\ttraining's binary_logloss: 0.239636\tvalid_1's binary_logloss: 0.245536\n",
      "[80]\ttraining's binary_logloss: 0.23838\tvalid_1's binary_logloss: 0.245446\n",
      "[90]\ttraining's binary_logloss: 0.237212\tvalid_1's binary_logloss: 0.245322\n",
      "[100]\ttraining's binary_logloss: 0.236166\tvalid_1's binary_logloss: 0.245298\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.236166\tvalid_1's binary_logloss: 0.245298\n",
      "ROC_AUC:0.7617061433216424\n",
      "0.06767633539585213\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.256104\tvalid_1's binary_logloss: 0.257829\n",
      "[20]\ttraining's binary_logloss: 0.249427\tvalid_1's binary_logloss: 0.252356\n",
      "[30]\ttraining's binary_logloss: 0.246052\tvalid_1's binary_logloss: 0.250197\n",
      "[40]\ttraining's binary_logloss: 0.24383\tvalid_1's binary_logloss: 0.249056\n",
      "[50]\ttraining's binary_logloss: 0.242089\tvalid_1's binary_logloss: 0.248402\n",
      "[60]\ttraining's binary_logloss: 0.240555\tvalid_1's binary_logloss: 0.247969\n",
      "[70]\ttraining's binary_logloss: 0.239163\tvalid_1's binary_logloss: 0.247874\n",
      "[80]\ttraining's binary_logloss: 0.237944\tvalid_1's binary_logloss: 0.247807\n",
      "[90]\ttraining's binary_logloss: 0.236777\tvalid_1's binary_logloss: 0.247776\n",
      "[100]\ttraining's binary_logloss: 0.235683\tvalid_1's binary_logloss: 0.247762\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.235683\tvalid_1's binary_logloss: 0.247762\n",
      "ROC_AUC:0.7524763857128757\n",
      "0.0681161839686123\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.256634\tvalid_1's binary_logloss: 0.256046\n",
      "[20]\ttraining's binary_logloss: 0.249895\tvalid_1's binary_logloss: 0.250541\n",
      "[30]\ttraining's binary_logloss: 0.246488\tvalid_1's binary_logloss: 0.248321\n",
      "[40]\ttraining's binary_logloss: 0.244189\tvalid_1's binary_logloss: 0.247191\n",
      "[50]\ttraining's binary_logloss: 0.242475\tvalid_1's binary_logloss: 0.246617\n",
      "[60]\ttraining's binary_logloss: 0.240941\tvalid_1's binary_logloss: 0.246161\n",
      "[70]\ttraining's binary_logloss: 0.23963\tvalid_1's binary_logloss: 0.246019\n",
      "[80]\ttraining's binary_logloss: 0.238338\tvalid_1's binary_logloss: 0.245903\n",
      "[90]\ttraining's binary_logloss: 0.237194\tvalid_1's binary_logloss: 0.245987\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.238555\tvalid_1's binary_logloss: 0.245881\n",
      "ROC_AUC:0.7520575176703684\n",
      "0.06742550135834664\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.254683\tvalid_1's binary_logloss: 0.263327\n",
      "[20]\ttraining's binary_logloss: 0.248104\tvalid_1's binary_logloss: 0.257757\n",
      "[30]\ttraining's binary_logloss: 0.244726\tvalid_1's binary_logloss: 0.255419\n",
      "[40]\ttraining's binary_logloss: 0.242558\tvalid_1's binary_logloss: 0.254359\n",
      "[50]\ttraining's binary_logloss: 0.240835\tvalid_1's binary_logloss: 0.25379\n",
      "[60]\ttraining's binary_logloss: 0.239333\tvalid_1's binary_logloss: 0.253447\n",
      "[70]\ttraining's binary_logloss: 0.237909\tvalid_1's binary_logloss: 0.253356\n",
      "[80]\ttraining's binary_logloss: 0.236602\tvalid_1's binary_logloss: 0.2532\n",
      "[90]\ttraining's binary_logloss: 0.235382\tvalid_1's binary_logloss: 0.253122\n",
      "[100]\ttraining's binary_logloss: 0.234105\tvalid_1's binary_logloss: 0.253087\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.234105\tvalid_1's binary_logloss: 0.253087\n",
      "ROC_AUC:0.7517931926889188\n",
      "0.06997857493435723\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.257013\tvalid_1's binary_logloss: 0.254101\n",
      "[20]\ttraining's binary_logloss: 0.250368\tvalid_1's binary_logloss: 0.248849\n",
      "[30]\ttraining's binary_logloss: 0.246935\tvalid_1's binary_logloss: 0.246705\n",
      "[40]\ttraining's binary_logloss: 0.244611\tvalid_1's binary_logloss: 0.245595\n",
      "[50]\ttraining's binary_logloss: 0.242861\tvalid_1's binary_logloss: 0.245088\n",
      "[60]\ttraining's binary_logloss: 0.241412\tvalid_1's binary_logloss: 0.244741\n",
      "[70]\ttraining's binary_logloss: 0.240009\tvalid_1's binary_logloss: 0.244571\n",
      "[80]\ttraining's binary_logloss: 0.238755\tvalid_1's binary_logloss: 0.24458\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.240134\tvalid_1's binary_logloss: 0.244565\n",
      "ROC_AUC:0.7524888739671246\n",
      "0.06705606277761306\n",
      "ROC_AUC:[0.7617061433216424, 0.7524763857128757, 0.7520575176703684, 0.7517931926889188, 0.7524888739671246]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([4.0406e+04, 1.2300e+04, 4.8300e+03, 2.1040e+03, 1.0100e+03,\n",
       "        4.9200e+02, 2.1300e+02, 1.0600e+02, 3.5000e+01, 6.0000e+00]),\n",
       " array([0.00719798, 0.07798408, 0.14877018, 0.21955629, 0.29034239,\n",
       "        0.36112849, 0.43191459, 0.5027007 , 0.5734868 , 0.6442729 ,\n",
       "        0.71505901]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_onehot.values\n",
    "y = df.TARGET.values\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',      # ２値分類\n",
    "    'max_depth': 10,            # 木の深さ\n",
    "    'learning_rate':0.1,         # 学習率\n",
    "    'num_class': 1,\n",
    "    'verbose': 10    \n",
    "}\n",
    "\n",
    "#評価値を平均化するためのリスト\n",
    "scores = []\n",
    "\n",
    "for t_index, v_index in kf.split(X):\n",
    "    X_train, y_train = X[t_index], y[t_index]\n",
    "    X_eval, y_eval = X[v_index],y[v_index]\n",
    "    \n",
    "    train_data = lgbm.Dataset(X_train, y_train)\n",
    "    eval_data = lgbm.Dataset(X_eval, y_eval)\n",
    "    \n",
    "    clf = lgbm.train(params=params,\n",
    "                      train_set=train_data,\n",
    "                      valid_sets=[train_data, eval_data],\n",
    "                      early_stopping_rounds=20,\n",
    "                      verbose_eval=10)\n",
    "\n",
    "    y_pred = clf.predict(X_eval)\n",
    "    mse_score = mean_squared_error(y_eval, y_pred)\n",
    "    print(\"ROC_AUC:{}\".format(roc_auc_score(y_eval, y_pred)))\n",
    "    scores.append(roc_auc_score(y_eval, y_pred))                             # 評価値を平均化するため,リストに追加していく\n",
    "    print(mse_score)\n",
    "\n",
    "print(\"ROC_AUC:{}\".format(scores))\n",
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMを使うことで、ROC_AUCが0.75～0.76ぐらいに向上した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ＬＧＢＭのハイパーパラメータをＯＰＴＵＮＡを使って探索してみる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：　https://www.codexa.net/lightgbm-beginner/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',      # ２値分類\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 200),            # 木の深さ\n",
    "        'learning_rate':trial.suggest_uniform('learning_rate', 0.1, 0.5),        # 学習率\n",
    "        'num_class': 1,\n",
    "        \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 200),            # LightGBMで最も重要。決定木の複雑度を調整します。\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 2, 200),            # 決定木のノード（葉）の最小データ数を指定\n",
    "       \n",
    "#         'feature_fraction' : trial.suggest_uniform('feature_fraction', 0.0, 1.0),\n",
    "#         'lambda_l1' : trial.suggest_uniform('lambda_l1' , 0.0, 1.0),\n",
    "#         'lambda_l2' : trial.suggest_uniform('lambda_l2' , 0.0, 1.0)\n",
    "    }\n",
    "              \n",
    "    \n",
    "    #評価値を平均化するためのリスト\n",
    "    scores = []\n",
    "\n",
    "    for t_index, v_index in kf.split(X):\n",
    "        X_train, y_train = X[t_index], y[t_index]\n",
    "        X_eval, y_eval = X[v_index],y[v_index]\n",
    "\n",
    "        train_data = lgbm.Dataset(X_train, y_train)\n",
    "        eval_data = lgbm.Dataset(X_eval, y_eval)\n",
    "\n",
    "        clf = lgbm.train(params=params,\n",
    "                         train_set=train_data,\n",
    "                         valid_sets=[train_data, eval_data],\n",
    "                         early_stopping_rounds=20,\n",
    "                         verbose_eval=10)\n",
    "\n",
    "        y_pred = clf.predict(X_eval)\n",
    "        score = roc_auc_score(y_eval, y_pred)\n",
    "        scores.append(score)                             # 評価値を平均化するため,リストに追加していく\n",
    "    \n",
    "    return np.mean(scores) # この評価値を良くするために、optuna は頑張ってくれる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.239529\tvalid_1's binary_logloss: 0.24992\n",
      "[20]\ttraining's binary_logloss: 0.230688\tvalid_1's binary_logloss: 0.251176\n",
      "[30]\ttraining's binary_logloss: 0.22254\tvalid_1's binary_logloss: 0.252491\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.238457\tvalid_1's binary_logloss: 0.249911\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.239167\tvalid_1's binary_logloss: 0.252251\n",
      "[20]\ttraining's binary_logloss: 0.229745\tvalid_1's binary_logloss: 0.252929\n",
      "[30]\ttraining's binary_logloss: 0.222431\tvalid_1's binary_logloss: 0.254629\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.236774\tvalid_1's binary_logloss: 0.251809\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.239367\tvalid_1's binary_logloss: 0.249826\n",
      "[20]\ttraining's binary_logloss: 0.230346\tvalid_1's binary_logloss: 0.251574\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.240506\tvalid_1's binary_logloss: 0.249657\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237696\tvalid_1's binary_logloss: 0.256102\n",
      "[20]\ttraining's binary_logloss: 0.228545\tvalid_1's binary_logloss: 0.258157\n",
      "[30]\ttraining's binary_logloss: 0.221114\tvalid_1's binary_logloss: 0.260238\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's binary_logloss: 0.237696\tvalid_1's binary_logloss: 0.256102\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.239779\tvalid_1's binary_logloss: 0.248614\n",
      "[20]\ttraining's binary_logloss: 0.230551\tvalid_1's binary_logloss: 0.25015\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.240736\tvalid_1's binary_logloss: 0.248482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:36:18,589] Finished trial#0 resulted in value: 0.7436878916258918. Current best value is 0.7436878916258918 with parameters: {'max_depth': 127, 'learning_rate': 0.44605842066873047, 'num_leaves': 72, 'min_data_in_leaf': 136}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238077\tvalid_1's binary_logloss: 0.251391\n",
      "[20]\ttraining's binary_logloss: 0.227845\tvalid_1's binary_logloss: 0.253547\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's binary_logloss: 0.240606\tvalid_1's binary_logloss: 0.251338\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237322\tvalid_1's binary_logloss: 0.253244\n",
      "[20]\ttraining's binary_logloss: 0.226972\tvalid_1's binary_logloss: 0.255782\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_logloss: 0.241231\tvalid_1's binary_logloss: 0.252904\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237897\tvalid_1's binary_logloss: 0.251144\n",
      "[20]\ttraining's binary_logloss: 0.227825\tvalid_1's binary_logloss: 0.253606\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.243449\tvalid_1's binary_logloss: 0.251078\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236188\tvalid_1's binary_logloss: 0.258355\n",
      "[20]\ttraining's binary_logloss: 0.226069\tvalid_1's binary_logloss: 0.261095\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.241573\tvalid_1's binary_logloss: 0.258162\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237981\tvalid_1's binary_logloss: 0.24997\n",
      "[20]\ttraining's binary_logloss: 0.228198\tvalid_1's binary_logloss: 0.25259\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.243825\tvalid_1's binary_logloss: 0.249595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:36:27,467] Finished trial#1 resulted in value: 0.7392466441589388. Current best value is 0.7392466441589388 with parameters: {'max_depth': 55, 'learning_rate': 0.46107053431365763, 'num_leaves': 80, 'min_data_in_leaf': 83}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237574\tvalid_1's binary_logloss: 0.248691\n",
      "[20]\ttraining's binary_logloss: 0.226493\tvalid_1's binary_logloss: 0.248294\n",
      "[30]\ttraining's binary_logloss: 0.2179\tvalid_1's binary_logloss: 0.248733\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.231471\tvalid_1's binary_logloss: 0.24797\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237132\tvalid_1's binary_logloss: 0.250528\n",
      "[20]\ttraining's binary_logloss: 0.225536\tvalid_1's binary_logloss: 0.249997\n",
      "[30]\ttraining's binary_logloss: 0.216905\tvalid_1's binary_logloss: 0.251592\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's binary_logloss: 0.231826\tvalid_1's binary_logloss: 0.249641\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237692\tvalid_1's binary_logloss: 0.248947\n",
      "[20]\ttraining's binary_logloss: 0.22649\tvalid_1's binary_logloss: 0.248849\n",
      "[30]\ttraining's binary_logloss: 0.218784\tvalid_1's binary_logloss: 0.250321\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.233816\tvalid_1's binary_logloss: 0.248283\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235532\tvalid_1's binary_logloss: 0.25646\n",
      "[20]\ttraining's binary_logloss: 0.22438\tvalid_1's binary_logloss: 0.25678\n",
      "[30]\ttraining's binary_logloss: 0.215222\tvalid_1's binary_logloss: 0.257724\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.23301\tvalid_1's binary_logloss: 0.256391\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237723\tvalid_1's binary_logloss: 0.248025\n",
      "[20]\ttraining's binary_logloss: 0.226497\tvalid_1's binary_logloss: 0.24825\n",
      "[30]\ttraining's binary_logloss: 0.218088\tvalid_1's binary_logloss: 0.249988\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.235114\tvalid_1's binary_logloss: 0.247965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:36:39,007] Finished trial#2 resulted in value: 0.7457133367402747. Current best value is 0.7392466441589388 with parameters: {'max_depth': 55, 'learning_rate': 0.46107053431365763, 'num_leaves': 80, 'min_data_in_leaf': 83}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.241111\tvalid_1's binary_logloss: 0.250852\n",
      "[20]\ttraining's binary_logloss: 0.229285\tvalid_1's binary_logloss: 0.248016\n",
      "[30]\ttraining's binary_logloss: 0.220247\tvalid_1's binary_logloss: 0.24761\n",
      "[40]\ttraining's binary_logloss: 0.21253\tvalid_1's binary_logloss: 0.247726\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.224519\tvalid_1's binary_logloss: 0.247505\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.240677\tvalid_1's binary_logloss: 0.252475\n",
      "[20]\ttraining's binary_logloss: 0.228928\tvalid_1's binary_logloss: 0.250092\n",
      "[30]\ttraining's binary_logloss: 0.219788\tvalid_1's binary_logloss: 0.249756\n",
      "[40]\ttraining's binary_logloss: 0.212129\tvalid_1's binary_logloss: 0.250272\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.220617\tvalid_1's binary_logloss: 0.249656\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.241034\tvalid_1's binary_logloss: 0.250373\n",
      "[20]\ttraining's binary_logloss: 0.229416\tvalid_1's binary_logloss: 0.248078\n",
      "[30]\ttraining's binary_logloss: 0.220415\tvalid_1's binary_logloss: 0.247913\n",
      "[40]\ttraining's binary_logloss: 0.212807\tvalid_1's binary_logloss: 0.24834\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.222126\tvalid_1's binary_logloss: 0.247875\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.239475\tvalid_1's binary_logloss: 0.257841\n",
      "[20]\ttraining's binary_logloss: 0.227626\tvalid_1's binary_logloss: 0.255823\n",
      "[30]\ttraining's binary_logloss: 0.218433\tvalid_1's binary_logloss: 0.255656\n",
      "[40]\ttraining's binary_logloss: 0.210785\tvalid_1's binary_logloss: 0.255973\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.22013\tvalid_1's binary_logloss: 0.255347\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.241496\tvalid_1's binary_logloss: 0.249326\n",
      "[20]\ttraining's binary_logloss: 0.229777\tvalid_1's binary_logloss: 0.247066\n",
      "[30]\ttraining's binary_logloss: 0.220414\tvalid_1's binary_logloss: 0.247199\n",
      "[40]\ttraining's binary_logloss: 0.212495\tvalid_1's binary_logloss: 0.247731\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.224858\tvalid_1's binary_logloss: 0.246971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:36:53,107] Finished trial#3 resulted in value: 0.7478728553974365. Current best value is 0.7392466441589388 with parameters: {'max_depth': 55, 'learning_rate': 0.46107053431365763, 'num_leaves': 80, 'min_data_in_leaf': 83}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236531\tvalid_1's binary_logloss: 0.249761\n",
      "[20]\ttraining's binary_logloss: 0.224519\tvalid_1's binary_logloss: 0.250034\n",
      "[30]\ttraining's binary_logloss: 0.214977\tvalid_1's binary_logloss: 0.251681\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.229912\tvalid_1's binary_logloss: 0.249475\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236057\tvalid_1's binary_logloss: 0.25183\n",
      "[20]\ttraining's binary_logloss: 0.223797\tvalid_1's binary_logloss: 0.25311\n",
      "[30]\ttraining's binary_logloss: 0.214214\tvalid_1's binary_logloss: 0.254804\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.234613\tvalid_1's binary_logloss: 0.251754\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236625\tvalid_1's binary_logloss: 0.249931\n",
      "[20]\ttraining's binary_logloss: 0.224182\tvalid_1's binary_logloss: 0.251192\n",
      "[30]\ttraining's binary_logloss: 0.215031\tvalid_1's binary_logloss: 0.252932\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.233643\tvalid_1's binary_logloss: 0.249666\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234677\tvalid_1's binary_logloss: 0.25787\n",
      "[20]\ttraining's binary_logloss: 0.222454\tvalid_1's binary_logloss: 0.259091\n",
      "[30]\ttraining's binary_logloss: 0.212323\tvalid_1's binary_logloss: 0.261274\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.231895\tvalid_1's binary_logloss: 0.257718\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236888\tvalid_1's binary_logloss: 0.248795\n",
      "[20]\ttraining's binary_logloss: 0.225013\tvalid_1's binary_logloss: 0.24947\n",
      "[30]\ttraining's binary_logloss: 0.21524\tvalid_1's binary_logloss: 0.251728\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.232912\tvalid_1's binary_logloss: 0.248495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:37:03,601] Finished trial#4 resulted in value: 0.7430934545180128. Current best value is 0.7392466441589388 with parameters: {'max_depth': 55, 'learning_rate': 0.46107053431365763, 'num_leaves': 80, 'min_data_in_leaf': 83}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.24081\tvalid_1's binary_logloss: 0.248983\n",
      "[20]\ttraining's binary_logloss: 0.232431\tvalid_1's binary_logloss: 0.249131\n",
      "[30]\ttraining's binary_logloss: 0.225932\tvalid_1's binary_logloss: 0.250537\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.237807\tvalid_1's binary_logloss: 0.248444\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.240714\tvalid_1's binary_logloss: 0.251207\n",
      "[20]\ttraining's binary_logloss: 0.232362\tvalid_1's binary_logloss: 0.251707\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.241734\tvalid_1's binary_logloss: 0.251064\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.240896\tvalid_1's binary_logloss: 0.249118\n",
      "[20]\ttraining's binary_logloss: 0.232957\tvalid_1's binary_logloss: 0.249923\n",
      "[30]\ttraining's binary_logloss: 0.226397\tvalid_1's binary_logloss: 0.250971\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.239939\tvalid_1's binary_logloss: 0.248922\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.239255\tvalid_1's binary_logloss: 0.256507\n",
      "[20]\ttraining's binary_logloss: 0.230855\tvalid_1's binary_logloss: 0.257292\n",
      "[30]\ttraining's binary_logloss: 0.224407\tvalid_1's binary_logloss: 0.258262\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.236315\tvalid_1's binary_logloss: 0.256314\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.241043\tvalid_1's binary_logloss: 0.247927\n",
      "[20]\ttraining's binary_logloss: 0.232762\tvalid_1's binary_logloss: 0.249015\n",
      "[30]\ttraining's binary_logloss: 0.226018\tvalid_1's binary_logloss: 0.249942\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's binary_logloss: 0.241043\tvalid_1's binary_logloss: 0.247927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:37:12,089] Finished trial#5 resulted in value: 0.7451478233890152. Current best value is 0.7392466441589388 with parameters: {'max_depth': 55, 'learning_rate': 0.46107053431365763, 'num_leaves': 80, 'min_data_in_leaf': 83}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.22639\tvalid_1's binary_logloss: 0.255551\n",
      "[20]\ttraining's binary_logloss: 0.207232\tvalid_1's binary_logloss: 0.259656\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.23591\tvalid_1's binary_logloss: 0.25385\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.225998\tvalid_1's binary_logloss: 0.256369\n",
      "[20]\ttraining's binary_logloss: 0.206182\tvalid_1's binary_logloss: 0.260366\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.238239\tvalid_1's binary_logloss: 0.254958\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.225895\tvalid_1's binary_logloss: 0.255053\n",
      "[20]\ttraining's binary_logloss: 0.206767\tvalid_1's binary_logloss: 0.260991\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.235748\tvalid_1's binary_logloss: 0.253666\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.224538\tvalid_1's binary_logloss: 0.262504\n",
      "[20]\ttraining's binary_logloss: 0.205068\tvalid_1's binary_logloss: 0.267385\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.234267\tvalid_1's binary_logloss: 0.261318\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.226159\tvalid_1's binary_logloss: 0.254274\n",
      "[20]\ttraining's binary_logloss: 0.207188\tvalid_1's binary_logloss: 0.258957\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.238897\tvalid_1's binary_logloss: 0.252556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:37:21,832] Finished trial#6 resulted in value: 0.7337552700407296. Current best value is 0.7337552700407296 with parameters: {'max_depth': 165, 'learning_rate': 0.4079732990955779, 'num_leaves': 174, 'min_data_in_leaf': 45}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244553\tvalid_1's binary_logloss: 0.248006\n",
      "[20]\ttraining's binary_logloss: 0.238955\tvalid_1's binary_logloss: 0.248056\n",
      "[30]\ttraining's binary_logloss: 0.234459\tvalid_1's binary_logloss: 0.248679\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.241347\tvalid_1's binary_logloss: 0.247667\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.24404\tvalid_1's binary_logloss: 0.250889\n",
      "[20]\ttraining's binary_logloss: 0.238353\tvalid_1's binary_logloss: 0.250657\n",
      "[30]\ttraining's binary_logloss: 0.234102\tvalid_1's binary_logloss: 0.251572\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.239312\tvalid_1's binary_logloss: 0.250389\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244521\tvalid_1's binary_logloss: 0.249016\n",
      "[20]\ttraining's binary_logloss: 0.23892\tvalid_1's binary_logloss: 0.248797\n",
      "[30]\ttraining's binary_logloss: 0.234317\tvalid_1's binary_logloss: 0.249696\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.240758\tvalid_1's binary_logloss: 0.248467\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.242656\tvalid_1's binary_logloss: 0.255488\n",
      "[20]\ttraining's binary_logloss: 0.237058\tvalid_1's binary_logloss: 0.255534\n",
      "[30]\ttraining's binary_logloss: 0.232334\tvalid_1's binary_logloss: 0.256373\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.238972\tvalid_1's binary_logloss: 0.255098\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244831\tvalid_1's binary_logloss: 0.247171\n",
      "[20]\ttraining's binary_logloss: 0.239206\tvalid_1's binary_logloss: 0.246868\n",
      "[30]\ttraining's binary_logloss: 0.234971\tvalid_1's binary_logloss: 0.247715\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.240972\tvalid_1's binary_logloss: 0.246528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:37:29,867] Finished trial#7 resulted in value: 0.7481464275326174. Current best value is 0.7337552700407296 with parameters: {'max_depth': 165, 'learning_rate': 0.4079732990955779, 'num_leaves': 174, 'min_data_in_leaf': 45}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238889\tvalid_1's binary_logloss: 0.25156\n",
      "[20]\ttraining's binary_logloss: 0.225597\tvalid_1's binary_logloss: 0.248925\n",
      "[30]\ttraining's binary_logloss: 0.214864\tvalid_1's binary_logloss: 0.248802\n",
      "[40]\ttraining's binary_logloss: 0.206308\tvalid_1's binary_logloss: 0.249169\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.222164\tvalid_1's binary_logloss: 0.24859\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238697\tvalid_1's binary_logloss: 0.25276\n",
      "[20]\ttraining's binary_logloss: 0.22516\tvalid_1's binary_logloss: 0.251269\n",
      "[30]\ttraining's binary_logloss: 0.214339\tvalid_1's binary_logloss: 0.251494\n",
      "[40]\ttraining's binary_logloss: 0.205137\tvalid_1's binary_logloss: 0.252066\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.218456\tvalid_1's binary_logloss: 0.251012\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.239135\tvalid_1's binary_logloss: 0.250609\n",
      "[20]\ttraining's binary_logloss: 0.225653\tvalid_1's binary_logloss: 0.24879\n",
      "[30]\ttraining's binary_logloss: 0.214789\tvalid_1's binary_logloss: 0.248957\n",
      "[40]\ttraining's binary_logloss: 0.205711\tvalid_1's binary_logloss: 0.249745\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.21895\tvalid_1's binary_logloss: 0.248649\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237474\tvalid_1's binary_logloss: 0.257977\n",
      "[20]\ttraining's binary_logloss: 0.223737\tvalid_1's binary_logloss: 0.256344\n",
      "[30]\ttraining's binary_logloss: 0.213121\tvalid_1's binary_logloss: 0.256325\n",
      "[40]\ttraining's binary_logloss: 0.204105\tvalid_1's binary_logloss: 0.256883\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.21523\tvalid_1's binary_logloss: 0.256176\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.239774\tvalid_1's binary_logloss: 0.249471\n",
      "[20]\ttraining's binary_logloss: 0.226306\tvalid_1's binary_logloss: 0.248084\n",
      "[30]\ttraining's binary_logloss: 0.215303\tvalid_1's binary_logloss: 0.248276\n",
      "[40]\ttraining's binary_logloss: 0.206114\tvalid_1's binary_logloss: 0.248722\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.222771\tvalid_1's binary_logloss: 0.247891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:37:47,596] Finished trial#8 resulted in value: 0.7457918340285171. Current best value is 0.7337552700407296 with parameters: {'max_depth': 165, 'learning_rate': 0.4079732990955779, 'num_leaves': 174, 'min_data_in_leaf': 45}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.240815\tvalid_1's binary_logloss: 0.251056\n",
      "[20]\ttraining's binary_logloss: 0.232819\tvalid_1's binary_logloss: 0.25449\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.241852\tvalid_1's binary_logloss: 0.251021\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.24003\tvalid_1's binary_logloss: 0.252971\n",
      "[20]\ttraining's binary_logloss: 0.231396\tvalid_1's binary_logloss: 0.255465\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's binary_logloss: 0.242016\tvalid_1's binary_logloss: 0.252673\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.240595\tvalid_1's binary_logloss: 0.250968\n",
      "[20]\ttraining's binary_logloss: 0.232322\tvalid_1's binary_logloss: 0.254281\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_logloss: 0.243892\tvalid_1's binary_logloss: 0.250616\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23884\tvalid_1's binary_logloss: 0.25876\n",
      "[20]\ttraining's binary_logloss: 0.23094\tvalid_1's binary_logloss: 0.262771\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's binary_logloss: 0.241008\tvalid_1's binary_logloss: 0.258109\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.240712\tvalid_1's binary_logloss: 0.249849\n",
      "[20]\ttraining's binary_logloss: 0.232764\tvalid_1's binary_logloss: 0.254228\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_logloss: 0.244162\tvalid_1's binary_logloss: 0.249384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 17:37:58,231] Finished trial#9 resulted in value: 0.7418080958013648. Current best value is 0.7337552700407296 with parameters: {'max_depth': 165, 'learning_rate': 0.4079732990955779, 'num_leaves': 174, 'min_data_in_leaf': 45}.\n"
     ]
    }
   ],
   "source": [
    "# optuna でハイパーパラメータの最適化\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10, timeout=180) # n_trials を大きくすると、チューニング回数がたくさん出来るかわりに遅くなる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 165, 'learning_rate': 0.4079732990955779, 'num_leaves': 174, 'min_data_in_leaf': 45}\n",
      "0.7337552700407296\n"
     ]
    }
   ],
   "source": [
    "# optuna が見つけてくれた結果を確認\n",
    "print(study.best_params)    # これが辞書型になっているので、確認時に利用が出来る\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要とされるパラメータ（num_leaves,max_depth）が肥大化しているにもかかわらず、ROC_AUCスコアはあまり向上しない。そこでグリッドサーチも使って検討してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7542113930124932\n",
      "{'max_depth': 8, 'min_data_in_leaf': 15, 'num_leaves': 45}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_data_in_leaf</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.876079</td>\n",
       "      <td>0.142486</td>\n",
       "      <td>0.076556</td>\n",
       "      <td>0.008132</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 8, 'min_data_in_leaf': 3, 'num_l...</td>\n",
       "      <td>0.740443</td>\n",
       "      <td>0.756698</td>\n",
       "      <td>0.751953</td>\n",
       "      <td>0.756615</td>\n",
       "      <td>0.752052</td>\n",
       "      <td>0.754460</td>\n",
       "      <td>0.749785</td>\n",
       "      <td>0.754574</td>\n",
       "      <td>0.760403</td>\n",
       "      <td>0.755769</td>\n",
       "      <td>0.753275</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.987701</td>\n",
       "      <td>0.054983</td>\n",
       "      <td>0.081306</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>{'max_depth': 8, 'min_data_in_leaf': 3, 'num_l...</td>\n",
       "      <td>0.739254</td>\n",
       "      <td>0.757467</td>\n",
       "      <td>0.753685</td>\n",
       "      <td>0.755837</td>\n",
       "      <td>0.752102</td>\n",
       "      <td>0.755801</td>\n",
       "      <td>0.747818</td>\n",
       "      <td>0.752249</td>\n",
       "      <td>0.759992</td>\n",
       "      <td>0.756786</td>\n",
       "      <td>0.753099</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.130553</td>\n",
       "      <td>0.034905</td>\n",
       "      <td>0.088107</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 8, 'min_data_in_leaf': 3, 'num_l...</td>\n",
       "      <td>0.738419</td>\n",
       "      <td>0.755672</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.756950</td>\n",
       "      <td>0.752606</td>\n",
       "      <td>0.755616</td>\n",
       "      <td>0.750305</td>\n",
       "      <td>0.752518</td>\n",
       "      <td>0.760005</td>\n",
       "      <td>0.757908</td>\n",
       "      <td>0.753343</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.834214</td>\n",
       "      <td>0.046989</td>\n",
       "      <td>0.077857</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 8, 'min_data_in_leaf': 9, 'num_l...</td>\n",
       "      <td>0.740562</td>\n",
       "      <td>0.757224</td>\n",
       "      <td>0.753186</td>\n",
       "      <td>0.756019</td>\n",
       "      <td>0.751173</td>\n",
       "      <td>0.754252</td>\n",
       "      <td>0.749376</td>\n",
       "      <td>0.754150</td>\n",
       "      <td>0.760241</td>\n",
       "      <td>0.755433</td>\n",
       "      <td>0.753161</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.029775</td>\n",
       "      <td>0.082685</td>\n",
       "      <td>0.093857</td>\n",
       "      <td>0.029678</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>{'max_depth': 8, 'min_data_in_leaf': 9, 'num_l...</td>\n",
       "      <td>0.742266</td>\n",
       "      <td>0.756001</td>\n",
       "      <td>0.752630</td>\n",
       "      <td>0.757341</td>\n",
       "      <td>0.751968</td>\n",
       "      <td>0.756138</td>\n",
       "      <td>0.750878</td>\n",
       "      <td>0.754337</td>\n",
       "      <td>0.761201</td>\n",
       "      <td>0.756136</td>\n",
       "      <td>0.753890</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.374883</td>\n",
       "      <td>0.204802</td>\n",
       "      <td>0.104508</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 8, 'min_data_in_leaf': 9, 'num_l...</td>\n",
       "      <td>0.740532</td>\n",
       "      <td>0.756744</td>\n",
       "      <td>0.753181</td>\n",
       "      <td>0.756399</td>\n",
       "      <td>0.752341</td>\n",
       "      <td>0.755064</td>\n",
       "      <td>0.748759</td>\n",
       "      <td>0.753046</td>\n",
       "      <td>0.759538</td>\n",
       "      <td>0.755924</td>\n",
       "      <td>0.753153</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.415697</td>\n",
       "      <td>0.040731</td>\n",
       "      <td>0.122109</td>\n",
       "      <td>0.036021</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 8, 'min_data_in_leaf': 15, 'num_...</td>\n",
       "      <td>0.741616</td>\n",
       "      <td>0.757248</td>\n",
       "      <td>0.753175</td>\n",
       "      <td>0.756330</td>\n",
       "      <td>0.751482</td>\n",
       "      <td>0.753551</td>\n",
       "      <td>0.749368</td>\n",
       "      <td>0.753298</td>\n",
       "      <td>0.760747</td>\n",
       "      <td>0.756216</td>\n",
       "      <td>0.753303</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.928517</td>\n",
       "      <td>1.044143</td>\n",
       "      <td>0.185471</td>\n",
       "      <td>0.061716</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>{'max_depth': 8, 'min_data_in_leaf': 15, 'num_...</td>\n",
       "      <td>0.742722</td>\n",
       "      <td>0.756699</td>\n",
       "      <td>0.754149</td>\n",
       "      <td>0.756906</td>\n",
       "      <td>0.752645</td>\n",
       "      <td>0.755511</td>\n",
       "      <td>0.750754</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.761803</td>\n",
       "      <td>0.756690</td>\n",
       "      <td>0.754211</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.972017</td>\n",
       "      <td>0.378095</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.050345</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 8, 'min_data_in_leaf': 15, 'num_...</td>\n",
       "      <td>0.740141</td>\n",
       "      <td>0.756574</td>\n",
       "      <td>0.753638</td>\n",
       "      <td>0.756620</td>\n",
       "      <td>0.753511</td>\n",
       "      <td>0.754747</td>\n",
       "      <td>0.749325</td>\n",
       "      <td>0.752028</td>\n",
       "      <td>0.761179</td>\n",
       "      <td>0.756642</td>\n",
       "      <td>0.753440</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.081392</td>\n",
       "      <td>0.294994</td>\n",
       "      <td>0.144373</td>\n",
       "      <td>0.027513</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 11, 'min_data_in_leaf': 3, 'num_...</td>\n",
       "      <td>0.740619</td>\n",
       "      <td>0.756162</td>\n",
       "      <td>0.751700</td>\n",
       "      <td>0.755966</td>\n",
       "      <td>0.752317</td>\n",
       "      <td>0.753791</td>\n",
       "      <td>0.748895</td>\n",
       "      <td>0.753782</td>\n",
       "      <td>0.759606</td>\n",
       "      <td>0.756068</td>\n",
       "      <td>0.752891</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.277960</td>\n",
       "      <td>0.396302</td>\n",
       "      <td>0.194080</td>\n",
       "      <td>0.067204</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>{'max_depth': 11, 'min_data_in_leaf': 3, 'num_...</td>\n",
       "      <td>0.741417</td>\n",
       "      <td>0.756236</td>\n",
       "      <td>0.752939</td>\n",
       "      <td>0.755309</td>\n",
       "      <td>0.752535</td>\n",
       "      <td>0.753998</td>\n",
       "      <td>0.748979</td>\n",
       "      <td>0.752972</td>\n",
       "      <td>0.759378</td>\n",
       "      <td>0.755380</td>\n",
       "      <td>0.752914</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.169270</td>\n",
       "      <td>0.212707</td>\n",
       "      <td>0.176942</td>\n",
       "      <td>0.049489</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 11, 'min_data_in_leaf': 3, 'num_...</td>\n",
       "      <td>0.741398</td>\n",
       "      <td>0.754903</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.755030</td>\n",
       "      <td>0.752140</td>\n",
       "      <td>0.753864</td>\n",
       "      <td>0.747415</td>\n",
       "      <td>0.750935</td>\n",
       "      <td>0.758391</td>\n",
       "      <td>0.755063</td>\n",
       "      <td>0.752119</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.540124</td>\n",
       "      <td>0.140673</td>\n",
       "      <td>0.149564</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 11, 'min_data_in_leaf': 9, 'num_...</td>\n",
       "      <td>0.740007</td>\n",
       "      <td>0.757157</td>\n",
       "      <td>0.752196</td>\n",
       "      <td>0.754872</td>\n",
       "      <td>0.752210</td>\n",
       "      <td>0.754101</td>\n",
       "      <td>0.749500</td>\n",
       "      <td>0.752793</td>\n",
       "      <td>0.759823</td>\n",
       "      <td>0.756215</td>\n",
       "      <td>0.752887</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.419750</td>\n",
       "      <td>0.635751</td>\n",
       "      <td>0.161868</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>{'max_depth': 11, 'min_data_in_leaf': 9, 'num_...</td>\n",
       "      <td>0.741631</td>\n",
       "      <td>0.756246</td>\n",
       "      <td>0.754254</td>\n",
       "      <td>0.756422</td>\n",
       "      <td>0.751599</td>\n",
       "      <td>0.753941</td>\n",
       "      <td>0.749352</td>\n",
       "      <td>0.752104</td>\n",
       "      <td>0.759164</td>\n",
       "      <td>0.755280</td>\n",
       "      <td>0.752999</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.637751</td>\n",
       "      <td>0.375272</td>\n",
       "      <td>0.170343</td>\n",
       "      <td>0.010473</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 11, 'min_data_in_leaf': 9, 'num_...</td>\n",
       "      <td>0.741528</td>\n",
       "      <td>0.754230</td>\n",
       "      <td>0.753292</td>\n",
       "      <td>0.754768</td>\n",
       "      <td>0.753157</td>\n",
       "      <td>0.753776</td>\n",
       "      <td>0.747180</td>\n",
       "      <td>0.753551</td>\n",
       "      <td>0.757568</td>\n",
       "      <td>0.757738</td>\n",
       "      <td>0.752679</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.087497</td>\n",
       "      <td>1.076275</td>\n",
       "      <td>0.160012</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 11, 'min_data_in_leaf': 15, 'num...</td>\n",
       "      <td>0.740943</td>\n",
       "      <td>0.757230</td>\n",
       "      <td>0.752040</td>\n",
       "      <td>0.755625</td>\n",
       "      <td>0.751596</td>\n",
       "      <td>0.754188</td>\n",
       "      <td>0.748525</td>\n",
       "      <td>0.753051</td>\n",
       "      <td>0.760698</td>\n",
       "      <td>0.756318</td>\n",
       "      <td>0.753021</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.874287</td>\n",
       "      <td>0.177635</td>\n",
       "      <td>0.160113</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>{'max_depth': 11, 'min_data_in_leaf': 15, 'num...</td>\n",
       "      <td>0.740991</td>\n",
       "      <td>0.755769</td>\n",
       "      <td>0.753269</td>\n",
       "      <td>0.754816</td>\n",
       "      <td>0.752108</td>\n",
       "      <td>0.755085</td>\n",
       "      <td>0.749465</td>\n",
       "      <td>0.752758</td>\n",
       "      <td>0.760053</td>\n",
       "      <td>0.756867</td>\n",
       "      <td>0.753118</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.064992</td>\n",
       "      <td>0.099189</td>\n",
       "      <td>0.173527</td>\n",
       "      <td>0.014214</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 11, 'min_data_in_leaf': 15, 'num...</td>\n",
       "      <td>0.740511</td>\n",
       "      <td>0.755848</td>\n",
       "      <td>0.751005</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.750966</td>\n",
       "      <td>0.754436</td>\n",
       "      <td>0.748955</td>\n",
       "      <td>0.753055</td>\n",
       "      <td>0.760675</td>\n",
       "      <td>0.757175</td>\n",
       "      <td>0.752929</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.487119</td>\n",
       "      <td>0.150719</td>\n",
       "      <td>0.142513</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 15, 'min_data_in_leaf': 3, 'num_...</td>\n",
       "      <td>0.740185</td>\n",
       "      <td>0.758094</td>\n",
       "      <td>0.752286</td>\n",
       "      <td>0.754921</td>\n",
       "      <td>0.752385</td>\n",
       "      <td>0.754760</td>\n",
       "      <td>0.748815</td>\n",
       "      <td>0.753205</td>\n",
       "      <td>0.758883</td>\n",
       "      <td>0.755842</td>\n",
       "      <td>0.752938</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.743172</td>\n",
       "      <td>0.454504</td>\n",
       "      <td>0.149464</td>\n",
       "      <td>0.017552</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>{'max_depth': 15, 'min_data_in_leaf': 3, 'num_...</td>\n",
       "      <td>0.740589</td>\n",
       "      <td>0.754954</td>\n",
       "      <td>0.751921</td>\n",
       "      <td>0.755983</td>\n",
       "      <td>0.749921</td>\n",
       "      <td>0.752621</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>0.752651</td>\n",
       "      <td>0.759185</td>\n",
       "      <td>0.754287</td>\n",
       "      <td>0.752020</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.356866</td>\n",
       "      <td>0.461951</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>0.049764</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 15, 'min_data_in_leaf': 3, 'num_...</td>\n",
       "      <td>0.740784</td>\n",
       "      <td>0.753581</td>\n",
       "      <td>0.751895</td>\n",
       "      <td>0.754978</td>\n",
       "      <td>0.750471</td>\n",
       "      <td>0.753624</td>\n",
       "      <td>0.748622</td>\n",
       "      <td>0.752498</td>\n",
       "      <td>0.758372</td>\n",
       "      <td>0.755839</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.672926</td>\n",
       "      <td>0.360036</td>\n",
       "      <td>0.109419</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 15, 'min_data_in_leaf': 9, 'num_...</td>\n",
       "      <td>0.739658</td>\n",
       "      <td>0.756993</td>\n",
       "      <td>0.751599</td>\n",
       "      <td>0.755687</td>\n",
       "      <td>0.751324</td>\n",
       "      <td>0.754226</td>\n",
       "      <td>0.748991</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.759287</td>\n",
       "      <td>0.756348</td>\n",
       "      <td>0.752783</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.294234</td>\n",
       "      <td>0.744065</td>\n",
       "      <td>0.129175</td>\n",
       "      <td>0.026936</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>{'max_depth': 15, 'min_data_in_leaf': 9, 'num_...</td>\n",
       "      <td>0.740959</td>\n",
       "      <td>0.755601</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.756547</td>\n",
       "      <td>0.750325</td>\n",
       "      <td>0.752367</td>\n",
       "      <td>0.748686</td>\n",
       "      <td>0.753624</td>\n",
       "      <td>0.759727</td>\n",
       "      <td>0.754751</td>\n",
       "      <td>0.752572</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.990998</td>\n",
       "      <td>0.079589</td>\n",
       "      <td>0.114161</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 15, 'min_data_in_leaf': 9, 'num_...</td>\n",
       "      <td>0.740437</td>\n",
       "      <td>0.756530</td>\n",
       "      <td>0.752608</td>\n",
       "      <td>0.754638</td>\n",
       "      <td>0.751969</td>\n",
       "      <td>0.752218</td>\n",
       "      <td>0.747647</td>\n",
       "      <td>0.752928</td>\n",
       "      <td>0.759441</td>\n",
       "      <td>0.756748</td>\n",
       "      <td>0.752516</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.077208</td>\n",
       "      <td>0.676731</td>\n",
       "      <td>0.110610</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 15, 'min_data_in_leaf': 15, 'num...</td>\n",
       "      <td>0.740284</td>\n",
       "      <td>0.758095</td>\n",
       "      <td>0.752246</td>\n",
       "      <td>0.755687</td>\n",
       "      <td>0.751952</td>\n",
       "      <td>0.754569</td>\n",
       "      <td>0.749018</td>\n",
       "      <td>0.753701</td>\n",
       "      <td>0.759805</td>\n",
       "      <td>0.756792</td>\n",
       "      <td>0.753215</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.604762</td>\n",
       "      <td>0.034674</td>\n",
       "      <td>0.110211</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>{'max_depth': 15, 'min_data_in_leaf': 15, 'num...</td>\n",
       "      <td>0.740096</td>\n",
       "      <td>0.755068</td>\n",
       "      <td>0.754187</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.752372</td>\n",
       "      <td>0.753666</td>\n",
       "      <td>0.748438</td>\n",
       "      <td>0.753880</td>\n",
       "      <td>0.759008</td>\n",
       "      <td>0.755862</td>\n",
       "      <td>0.752858</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>3.527601</td>\n",
       "      <td>0.856623</td>\n",
       "      <td>0.146665</td>\n",
       "      <td>0.038259</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 15, 'min_data_in_leaf': 15, 'num...</td>\n",
       "      <td>0.740856</td>\n",
       "      <td>0.754878</td>\n",
       "      <td>0.753030</td>\n",
       "      <td>0.755441</td>\n",
       "      <td>0.751867</td>\n",
       "      <td>0.752506</td>\n",
       "      <td>0.748886</td>\n",
       "      <td>0.753789</td>\n",
       "      <td>0.759055</td>\n",
       "      <td>0.756498</td>\n",
       "      <td>0.752681</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.876079      0.142486         0.076556        0.008132   \n",
       "1        1.987701      0.054983         0.081306        0.002831   \n",
       "2        2.130553      0.034905         0.088107        0.003145   \n",
       "3        1.834214      0.046989         0.077857        0.002190   \n",
       "4        2.029775      0.082685         0.093857        0.029678   \n",
       "5        2.374883      0.204802         0.104508        0.014074   \n",
       "6        2.415697      0.040731         0.122109        0.036021   \n",
       "7        3.928517      1.044143         0.185471        0.061716   \n",
       "8        4.972017      0.378095         0.218218        0.050345   \n",
       "9        3.081392      0.294994         0.144373        0.027513   \n",
       "10       4.277960      0.396302         0.194080        0.067204   \n",
       "11       4.169270      0.212707         0.176942        0.049489   \n",
       "12       3.540124      0.140673         0.149564        0.007147   \n",
       "13       4.419750      0.635751         0.161868        0.007911   \n",
       "14       4.637751      0.375272         0.170343        0.010473   \n",
       "15       4.087497      1.076275         0.160012        0.021301   \n",
       "16       3.874287      0.177635         0.160113        0.005789   \n",
       "17       4.064992      0.099189         0.173527        0.014214   \n",
       "18       3.487119      0.150719         0.142513        0.002111   \n",
       "19       3.743172      0.454504         0.149464        0.017552   \n",
       "20       3.356866      0.461951         0.135714        0.049764   \n",
       "21       2.672926      0.360036         0.109419        0.019974   \n",
       "22       3.294234      0.744065         0.129175        0.026936   \n",
       "23       2.990998      0.079589         0.114161        0.004111   \n",
       "24       3.077208      0.676731         0.110610        0.008274   \n",
       "25       2.604762      0.034674         0.110211        0.004356   \n",
       "26       3.527601      0.856623         0.146665        0.038259   \n",
       "\n",
       "   param_max_depth param_min_data_in_leaf param_num_leaves  \\\n",
       "0                8                      3               31   \n",
       "1                8                      3               45   \n",
       "2                8                      3               60   \n",
       "3                8                      9               31   \n",
       "4                8                      9               45   \n",
       "5                8                      9               60   \n",
       "6                8                     15               31   \n",
       "7                8                     15               45   \n",
       "8                8                     15               60   \n",
       "9               11                      3               31   \n",
       "10              11                      3               45   \n",
       "11              11                      3               60   \n",
       "12              11                      9               31   \n",
       "13              11                      9               45   \n",
       "14              11                      9               60   \n",
       "15              11                     15               31   \n",
       "16              11                     15               45   \n",
       "17              11                     15               60   \n",
       "18              15                      3               31   \n",
       "19              15                      3               45   \n",
       "20              15                      3               60   \n",
       "21              15                      9               31   \n",
       "22              15                      9               45   \n",
       "23              15                      9               60   \n",
       "24              15                     15               31   \n",
       "25              15                     15               45   \n",
       "26              15                     15               60   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_depth': 8, 'min_data_in_leaf': 3, 'num_l...           0.740443   \n",
       "1   {'max_depth': 8, 'min_data_in_leaf': 3, 'num_l...           0.739254   \n",
       "2   {'max_depth': 8, 'min_data_in_leaf': 3, 'num_l...           0.738419   \n",
       "3   {'max_depth': 8, 'min_data_in_leaf': 9, 'num_l...           0.740562   \n",
       "4   {'max_depth': 8, 'min_data_in_leaf': 9, 'num_l...           0.742266   \n",
       "5   {'max_depth': 8, 'min_data_in_leaf': 9, 'num_l...           0.740532   \n",
       "6   {'max_depth': 8, 'min_data_in_leaf': 15, 'num_...           0.741616   \n",
       "7   {'max_depth': 8, 'min_data_in_leaf': 15, 'num_...           0.742722   \n",
       "8   {'max_depth': 8, 'min_data_in_leaf': 15, 'num_...           0.740141   \n",
       "9   {'max_depth': 11, 'min_data_in_leaf': 3, 'num_...           0.740619   \n",
       "10  {'max_depth': 11, 'min_data_in_leaf': 3, 'num_...           0.741417   \n",
       "11  {'max_depth': 11, 'min_data_in_leaf': 3, 'num_...           0.741398   \n",
       "12  {'max_depth': 11, 'min_data_in_leaf': 9, 'num_...           0.740007   \n",
       "13  {'max_depth': 11, 'min_data_in_leaf': 9, 'num_...           0.741631   \n",
       "14  {'max_depth': 11, 'min_data_in_leaf': 9, 'num_...           0.741528   \n",
       "15  {'max_depth': 11, 'min_data_in_leaf': 15, 'num...           0.740943   \n",
       "16  {'max_depth': 11, 'min_data_in_leaf': 15, 'num...           0.740991   \n",
       "17  {'max_depth': 11, 'min_data_in_leaf': 15, 'num...           0.740511   \n",
       "18  {'max_depth': 15, 'min_data_in_leaf': 3, 'num_...           0.740185   \n",
       "19  {'max_depth': 15, 'min_data_in_leaf': 3, 'num_...           0.740589   \n",
       "20  {'max_depth': 15, 'min_data_in_leaf': 3, 'num_...           0.740784   \n",
       "21  {'max_depth': 15, 'min_data_in_leaf': 9, 'num_...           0.739658   \n",
       "22  {'max_depth': 15, 'min_data_in_leaf': 9, 'num_...           0.740959   \n",
       "23  {'max_depth': 15, 'min_data_in_leaf': 9, 'num_...           0.740437   \n",
       "24  {'max_depth': 15, 'min_data_in_leaf': 15, 'num...           0.740284   \n",
       "25  {'max_depth': 15, 'min_data_in_leaf': 15, 'num...           0.740096   \n",
       "26  {'max_depth': 15, 'min_data_in_leaf': 15, 'num...           0.740856   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.756698           0.751953           0.756615   \n",
       "1            0.757467           0.753685           0.755837   \n",
       "2            0.755672           0.753437           0.756950   \n",
       "3            0.757224           0.753186           0.756019   \n",
       "4            0.756001           0.752630           0.757341   \n",
       "5            0.756744           0.753181           0.756399   \n",
       "6            0.757248           0.753175           0.756330   \n",
       "7            0.756699           0.754149           0.756906   \n",
       "8            0.756574           0.753638           0.756620   \n",
       "9            0.756162           0.751700           0.755966   \n",
       "10           0.756236           0.752939           0.755309   \n",
       "11           0.754903           0.752053           0.755030   \n",
       "12           0.757157           0.752196           0.754872   \n",
       "13           0.756246           0.754254           0.756422   \n",
       "14           0.754230           0.753292           0.754768   \n",
       "15           0.757230           0.752040           0.755625   \n",
       "16           0.755769           0.753269           0.754816   \n",
       "17           0.755848           0.751005           0.756667   \n",
       "18           0.758094           0.752286           0.754921   \n",
       "19           0.754954           0.751921           0.755983   \n",
       "20           0.753581           0.751895           0.754978   \n",
       "21           0.756993           0.751599           0.755687   \n",
       "22           0.755601           0.753138           0.756547   \n",
       "23           0.756530           0.752608           0.754638   \n",
       "24           0.758095           0.752246           0.755687   \n",
       "25           0.755068           0.754187           0.756000   \n",
       "26           0.754878           0.753030           0.755441   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.752052           0.754460           0.749785   \n",
       "1            0.752102           0.755801           0.747818   \n",
       "2            0.752606           0.755616           0.750305   \n",
       "3            0.751173           0.754252           0.749376   \n",
       "4            0.751968           0.756138           0.750878   \n",
       "5            0.752341           0.755064           0.748759   \n",
       "6            0.751482           0.753551           0.749368   \n",
       "7            0.752645           0.755511           0.750754   \n",
       "8            0.753511           0.754747           0.749325   \n",
       "9            0.752317           0.753791           0.748895   \n",
       "10           0.752535           0.753998           0.748979   \n",
       "11           0.752140           0.753864           0.747415   \n",
       "12           0.752210           0.754101           0.749500   \n",
       "13           0.751599           0.753941           0.749352   \n",
       "14           0.753157           0.753776           0.747180   \n",
       "15           0.751596           0.754188           0.748525   \n",
       "16           0.752108           0.755085           0.749465   \n",
       "17           0.750966           0.754436           0.748955   \n",
       "18           0.752385           0.754760           0.748815   \n",
       "19           0.749921           0.752621           0.748092   \n",
       "20           0.750471           0.753624           0.748622   \n",
       "21           0.751324           0.754226           0.748991   \n",
       "22           0.750325           0.752367           0.748686   \n",
       "23           0.751969           0.752218           0.747647   \n",
       "24           0.751952           0.754569           0.749018   \n",
       "25           0.752372           0.753666           0.748438   \n",
       "26           0.751867           0.752506           0.748886   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.754574           0.760403           0.755769         0.753275   \n",
       "1            0.752249           0.759992           0.756786         0.753099   \n",
       "2            0.752518           0.760005           0.757908         0.753343   \n",
       "3            0.754150           0.760241           0.755433         0.753161   \n",
       "4            0.754337           0.761201           0.756136         0.753890   \n",
       "5            0.753046           0.759538           0.755924         0.753153   \n",
       "6            0.753298           0.760747           0.756216         0.753303   \n",
       "7            0.754237           0.761803           0.756690         0.754211   \n",
       "8            0.752028           0.761179           0.756642         0.753440   \n",
       "9            0.753782           0.759606           0.756068         0.752891   \n",
       "10           0.752972           0.759378           0.755380         0.752914   \n",
       "11           0.750935           0.758391           0.755063         0.752119   \n",
       "12           0.752793           0.759823           0.756215         0.752887   \n",
       "13           0.752104           0.759164           0.755280         0.752999   \n",
       "14           0.753551           0.757568           0.757738         0.752679   \n",
       "15           0.753051           0.760698           0.756318         0.753021   \n",
       "16           0.752758           0.760053           0.756867         0.753118   \n",
       "17           0.753055           0.760675           0.757175         0.752929   \n",
       "18           0.753205           0.758883           0.755842         0.752938   \n",
       "19           0.752651           0.759185           0.754287         0.752020   \n",
       "20           0.752498           0.758372           0.755839         0.752066   \n",
       "21           0.753716           0.759287           0.756348         0.752783   \n",
       "22           0.753624           0.759727           0.754751         0.752572   \n",
       "23           0.752928           0.759441           0.756748         0.752516   \n",
       "24           0.753701           0.759805           0.756792         0.753215   \n",
       "25           0.753880           0.759008           0.755862         0.752858   \n",
       "26           0.753789           0.759055           0.756498         0.752681   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.005129                6  \n",
       "1         0.005627               11  \n",
       "2         0.005675                4  \n",
       "3         0.005091                8  \n",
       "4         0.004792                2  \n",
       "5         0.005048                9  \n",
       "6         0.004941                5  \n",
       "7         0.004747                1  \n",
       "8         0.005363                3  \n",
       "9         0.004952               17  \n",
       "10        0.004622               16  \n",
       "11        0.004536               25  \n",
       "12        0.005110               18  \n",
       "13        0.004618               13  \n",
       "14        0.004620               22  \n",
       "15        0.005145               12  \n",
       "16        0.004873               10  \n",
       "17        0.005295               15  \n",
       "18        0.005080               14  \n",
       "19        0.004817               27  \n",
       "20        0.004573               26  \n",
       "21        0.005237               20  \n",
       "22        0.004872               23  \n",
       "23        0.005066               24  \n",
       "24        0.005250                7  \n",
       "25        0.004977               19  \n",
       "26        0.004732               21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=1)\n",
    "\n",
    "params = {'max_depth': [8,11,15],            # 木の深さ\n",
    "          \"min_data_in_leaf\": [3, 9, 15],\n",
    "          \"num_leaves\": [31, 45, 60],\n",
    "         }\n",
    "grid_search = GridSearchCV(light_gbm,  # 分類器を渡す\n",
    "                           param_grid=params,  # 試行してほしいパラメータを渡す\n",
    "                           cv=skf,  # 5-Fold stratified で汎化性能を調べる\n",
    "                           scoring = \"roc_auc\"\n",
    "                           )\n",
    "\n",
    "# グリッドサーチで優れたハイパーパラメータを探す\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(grid_search.best_score_)  # 最も良かったスコア\n",
    "print(grid_search.best_params_)  # 上記を記録したパラメータの組み合わせ\n",
    "\n",
    "display(pd.DataFrame(grid_search.cv_results_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 現状では、グリッドサーチによる{'max_depth': 8, 'min_data_in_leaf': 15, 'num_leaves': 45}のパラメータでベストなパフォーマンスとなっている（ROC_AUC＝0.7542113930124932）。  \n",
    "\n",
    "## そこで、上記のグリッドサーチ探索範囲に対応して再びオプチュナを試してみる。また、study_optimizeのn_trialsを30として最適化試行回数を多くして実行する。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',      # ２値分類\n",
    "        'max_depth':trial.suggest_int('max_depth', 8, 20),            # 木の深さ\n",
    "        'learning_rate':0.2,                                           # 学習率\n",
    "        'num_class':1,\n",
    "        \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 30, 80),            # LightGBMで最も重要。決定木の複雑度を調整します。\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 3, 20),            # 決定木のノード（葉）の最小データ数を指定   \n",
    "        \n",
    "#         'feature_fraction' : trial.suggest_uniform('feature_fraction', 0.0, 1.0),\n",
    "#         'lambda_l1' : trial.suggest_uniform('lambda_l1' , 0.0, 1.0),\n",
    "#         'lambda_l2' : trial.suggest_uniform('lambda_l2' , 0.0, 1.0)\n",
    "    }\n",
    "              \n",
    "    \n",
    "    #評価値を平均化するためのリスト\n",
    "    scores = []\n",
    "\n",
    "    for t_index, v_index in kf.split(X):\n",
    "        X_train, y_train = X[t_index], y[t_index]\n",
    "        X_eval, y_eval = X[v_index],y[v_index]\n",
    "\n",
    "        train_data = lgbm.Dataset(X_train, y_train)\n",
    "        eval_data = lgbm.Dataset(X_eval, y_eval)\n",
    "\n",
    "        clf = lgbm.train(params=params,\n",
    "                         train_set=train_data,\n",
    "                         valid_sets=[train_data, eval_data],\n",
    "                         early_stopping_rounds=20,\n",
    "                         verbose_eval=10)\n",
    "\n",
    "        y_pred = clf.predict(X_eval)\n",
    "        score = roc_auc_score(y_eval, y_pred)\n",
    "        scores.append(score)                             # 評価値を平均化するため,リストに追加していく\n",
    "    \n",
    "    return np.mean(scores) # この評価値を良くするために、optuna は頑張ってくれる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246216\tvalid_1's binary_logloss: 0.250254\n",
      "[20]\ttraining's binary_logloss: 0.238422\tvalid_1's binary_logloss: 0.247661\n",
      "[30]\ttraining's binary_logloss: 0.232855\tvalid_1's binary_logloss: 0.247695\n",
      "[40]\ttraining's binary_logloss: 0.227823\tvalid_1's binary_logloss: 0.248309\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's binary_logloss: 0.237229\tvalid_1's binary_logloss: 0.247452\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245872\tvalid_1's binary_logloss: 0.251917\n",
      "[20]\ttraining's binary_logloss: 0.238063\tvalid_1's binary_logloss: 0.250144\n",
      "[30]\ttraining's binary_logloss: 0.232247\tvalid_1's binary_logloss: 0.250282\n",
      "[40]\ttraining's binary_logloss: 0.226964\tvalid_1's binary_logloss: 0.250885\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.237388\tvalid_1's binary_logloss: 0.25\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246306\tvalid_1's binary_logloss: 0.250027\n",
      "[20]\ttraining's binary_logloss: 0.238331\tvalid_1's binary_logloss: 0.248243\n",
      "[30]\ttraining's binary_logloss: 0.232659\tvalid_1's binary_logloss: 0.248367\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's binary_logloss: 0.238999\tvalid_1's binary_logloss: 0.248133\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244383\tvalid_1's binary_logloss: 0.257114\n",
      "[20]\ttraining's binary_logloss: 0.236596\tvalid_1's binary_logloss: 0.255318\n",
      "[30]\ttraining's binary_logloss: 0.230599\tvalid_1's binary_logloss: 0.255667\n",
      "[40]\ttraining's binary_logloss: 0.225675\tvalid_1's binary_logloss: 0.255918\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.235964\tvalid_1's binary_logloss: 0.255163\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246588\tvalid_1's binary_logloss: 0.24895\n",
      "[20]\ttraining's binary_logloss: 0.238512\tvalid_1's binary_logloss: 0.247184\n",
      "[30]\ttraining's binary_logloss: 0.232643\tvalid_1's binary_logloss: 0.24721\n",
      "[40]\ttraining's binary_logloss: 0.227594\tvalid_1's binary_logloss: 0.247852\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.234753\tvalid_1's binary_logloss: 0.246996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:07:40,103] Finished trial#0 resulted in value: 0.7484117954775711. Current best value is 0.7484117954775711 with parameters: {'max_depth': 18, 'num_leaves': 62, 'min_data_in_leaf': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.249339\tvalid_1's binary_logloss: 0.250585\n",
      "[20]\ttraining's binary_logloss: 0.243786\tvalid_1's binary_logloss: 0.247401\n",
      "[30]\ttraining's binary_logloss: 0.240351\tvalid_1's binary_logloss: 0.246692\n",
      "[40]\ttraining's binary_logloss: 0.237446\tvalid_1's binary_logloss: 0.246416\n",
      "[50]\ttraining's binary_logloss: 0.23517\tvalid_1's binary_logloss: 0.246399\n",
      "[60]\ttraining's binary_logloss: 0.232693\tvalid_1's binary_logloss: 0.246535\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.236272\tvalid_1's binary_logloss: 0.246337\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.248739\tvalid_1's binary_logloss: 0.252103\n",
      "[20]\ttraining's binary_logloss: 0.243073\tvalid_1's binary_logloss: 0.248963\n",
      "[30]\ttraining's binary_logloss: 0.239828\tvalid_1's binary_logloss: 0.248246\n",
      "[40]\ttraining's binary_logloss: 0.236937\tvalid_1's binary_logloss: 0.248368\n",
      "[50]\ttraining's binary_logloss: 0.234353\tvalid_1's binary_logloss: 0.248435\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.237997\tvalid_1's binary_logloss: 0.248145\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.249264\tvalid_1's binary_logloss: 0.250411\n",
      "[20]\ttraining's binary_logloss: 0.243687\tvalid_1's binary_logloss: 0.247345\n",
      "[30]\ttraining's binary_logloss: 0.240197\tvalid_1's binary_logloss: 0.246767\n",
      "[40]\ttraining's binary_logloss: 0.237261\tvalid_1's binary_logloss: 0.246796\n",
      "[50]\ttraining's binary_logloss: 0.234763\tvalid_1's binary_logloss: 0.247121\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.238658\tvalid_1's binary_logloss: 0.24676\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247504\tvalid_1's binary_logloss: 0.257697\n",
      "[20]\ttraining's binary_logloss: 0.241953\tvalid_1's binary_logloss: 0.254656\n",
      "[30]\ttraining's binary_logloss: 0.238523\tvalid_1's binary_logloss: 0.254036\n",
      "[40]\ttraining's binary_logloss: 0.235483\tvalid_1's binary_logloss: 0.253701\n",
      "[50]\ttraining's binary_logloss: 0.232817\tvalid_1's binary_logloss: 0.254027\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.2358\tvalid_1's binary_logloss: 0.253639\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.249725\tvalid_1's binary_logloss: 0.248793\n",
      "[20]\ttraining's binary_logloss: 0.244106\tvalid_1's binary_logloss: 0.246175\n",
      "[30]\ttraining's binary_logloss: 0.24058\tvalid_1's binary_logloss: 0.245711\n",
      "[40]\ttraining's binary_logloss: 0.237731\tvalid_1's binary_logloss: 0.245903\n",
      "[50]\ttraining's binary_logloss: 0.23521\tvalid_1's binary_logloss: 0.246205\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.240227\tvalid_1's binary_logloss: 0.245631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:07:50,273] Finished trial#1 resulted in value: 0.751913930609063. Current best value is 0.7484117954775711 with parameters: {'max_depth': 18, 'num_leaves': 62, 'min_data_in_leaf': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246751\tvalid_1's binary_logloss: 0.250168\n",
      "[20]\ttraining's binary_logloss: 0.239538\tvalid_1's binary_logloss: 0.247679\n",
      "[30]\ttraining's binary_logloss: 0.234225\tvalid_1's binary_logloss: 0.247546\n",
      "[40]\ttraining's binary_logloss: 0.229766\tvalid_1's binary_logloss: 0.247745\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.235152\tvalid_1's binary_logloss: 0.247405\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246359\tvalid_1's binary_logloss: 0.251922\n",
      "[20]\ttraining's binary_logloss: 0.23895\tvalid_1's binary_logloss: 0.250343\n",
      "[30]\ttraining's binary_logloss: 0.233288\tvalid_1's binary_logloss: 0.250011\n",
      "[40]\ttraining's binary_logloss: 0.228886\tvalid_1's binary_logloss: 0.250157\n",
      "[50]\ttraining's binary_logloss: 0.22516\tvalid_1's binary_logloss: 0.250787\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.230974\tvalid_1's binary_logloss: 0.249941\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246861\tvalid_1's binary_logloss: 0.250012\n",
      "[20]\ttraining's binary_logloss: 0.239743\tvalid_1's binary_logloss: 0.247838\n",
      "[30]\ttraining's binary_logloss: 0.234535\tvalid_1's binary_logloss: 0.248055\n",
      "[40]\ttraining's binary_logloss: 0.229999\tvalid_1's binary_logloss: 0.248758\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.239147\tvalid_1's binary_logloss: 0.247771\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245286\tvalid_1's binary_logloss: 0.257371\n",
      "[20]\ttraining's binary_logloss: 0.237953\tvalid_1's binary_logloss: 0.255047\n",
      "[30]\ttraining's binary_logloss: 0.232662\tvalid_1's binary_logloss: 0.255099\n",
      "[40]\ttraining's binary_logloss: 0.228258\tvalid_1's binary_logloss: 0.256184\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.237953\tvalid_1's binary_logloss: 0.255047\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247261\tvalid_1's binary_logloss: 0.248621\n",
      "[20]\ttraining's binary_logloss: 0.239911\tvalid_1's binary_logloss: 0.246474\n",
      "[30]\ttraining's binary_logloss: 0.234508\tvalid_1's binary_logloss: 0.246755\n",
      "[40]\ttraining's binary_logloss: 0.229855\tvalid_1's binary_logloss: 0.247847\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.238282\tvalid_1's binary_logloss: 0.246393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:07:59,955] Finished trial#2 resulted in value: 0.7496797276984916. Current best value is 0.7484117954775711 with parameters: {'max_depth': 18, 'num_leaves': 62, 'min_data_in_leaf': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247381\tvalid_1's binary_logloss: 0.250198\n",
      "[20]\ttraining's binary_logloss: 0.240465\tvalid_1's binary_logloss: 0.247223\n",
      "[30]\ttraining's binary_logloss: 0.235532\tvalid_1's binary_logloss: 0.246863\n",
      "[40]\ttraining's binary_logloss: 0.231249\tvalid_1's binary_logloss: 0.24691\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.236427\tvalid_1's binary_logloss: 0.246742\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246834\tvalid_1's binary_logloss: 0.251825\n",
      "[20]\ttraining's binary_logloss: 0.239799\tvalid_1's binary_logloss: 0.249309\n",
      "[30]\ttraining's binary_logloss: 0.234755\tvalid_1's binary_logloss: 0.248843\n",
      "[40]\ttraining's binary_logloss: 0.23042\tvalid_1's binary_logloss: 0.249213\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.23568\tvalid_1's binary_logloss: 0.248708\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247291\tvalid_1's binary_logloss: 0.250134\n",
      "[20]\ttraining's binary_logloss: 0.24029\tvalid_1's binary_logloss: 0.247858\n",
      "[30]\ttraining's binary_logloss: 0.235358\tvalid_1's binary_logloss: 0.247521\n",
      "[40]\ttraining's binary_logloss: 0.231166\tvalid_1's binary_logloss: 0.247941\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.236748\tvalid_1's binary_logloss: 0.247375\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245534\tvalid_1's binary_logloss: 0.257365\n",
      "[20]\ttraining's binary_logloss: 0.238604\tvalid_1's binary_logloss: 0.254951\n",
      "[30]\ttraining's binary_logloss: 0.23355\tvalid_1's binary_logloss: 0.254928\n",
      "[40]\ttraining's binary_logloss: 0.229378\tvalid_1's binary_logloss: 0.25524\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.237029\tvalid_1's binary_logloss: 0.254827\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247502\tvalid_1's binary_logloss: 0.248415\n",
      "[20]\ttraining's binary_logloss: 0.240574\tvalid_1's binary_logloss: 0.246177\n",
      "[30]\ttraining's binary_logloss: 0.2353\tvalid_1's binary_logloss: 0.246076\n",
      "[40]\ttraining's binary_logloss: 0.231166\tvalid_1's binary_logloss: 0.246437\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.236726\tvalid_1's binary_logloss: 0.245947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:08:09,833] Finished trial#3 resulted in value: 0.7504597133106442. Current best value is 0.7484117954775711 with parameters: {'max_depth': 18, 'num_leaves': 62, 'min_data_in_leaf': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.249122\tvalid_1's binary_logloss: 0.25076\n",
      "[20]\ttraining's binary_logloss: 0.243174\tvalid_1's binary_logloss: 0.247312\n",
      "[30]\ttraining's binary_logloss: 0.239423\tvalid_1's binary_logloss: 0.246696\n",
      "[40]\ttraining's binary_logloss: 0.236101\tvalid_1's binary_logloss: 0.246248\n",
      "[50]\ttraining's binary_logloss: 0.233277\tvalid_1's binary_logloss: 0.246417\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.236419\tvalid_1's binary_logloss: 0.246223\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.248702\tvalid_1's binary_logloss: 0.252291\n",
      "[20]\ttraining's binary_logloss: 0.242744\tvalid_1's binary_logloss: 0.249331\n",
      "[30]\ttraining's binary_logloss: 0.238906\tvalid_1's binary_logloss: 0.248817\n",
      "[40]\ttraining's binary_logloss: 0.235608\tvalid_1's binary_logloss: 0.249096\n",
      "[50]\ttraining's binary_logloss: 0.232913\tvalid_1's binary_logloss: 0.249718\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.238467\tvalid_1's binary_logloss: 0.248748\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.249006\tvalid_1's binary_logloss: 0.250248\n",
      "[20]\ttraining's binary_logloss: 0.243192\tvalid_1's binary_logloss: 0.247718\n",
      "[30]\ttraining's binary_logloss: 0.239415\tvalid_1's binary_logloss: 0.247252\n",
      "[40]\ttraining's binary_logloss: 0.236064\tvalid_1's binary_logloss: 0.247653\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.239715\tvalid_1's binary_logloss: 0.247185\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247364\tvalid_1's binary_logloss: 0.257749\n",
      "[20]\ttraining's binary_logloss: 0.241496\tvalid_1's binary_logloss: 0.25517\n",
      "[30]\ttraining's binary_logloss: 0.237494\tvalid_1's binary_logloss: 0.254874\n",
      "[40]\ttraining's binary_logloss: 0.234391\tvalid_1's binary_logloss: 0.255162\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.238348\tvalid_1's binary_logloss: 0.254851\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.249513\tvalid_1's binary_logloss: 0.248694\n",
      "[20]\ttraining's binary_logloss: 0.243696\tvalid_1's binary_logloss: 0.246321\n",
      "[30]\ttraining's binary_logloss: 0.239823\tvalid_1's binary_logloss: 0.24597\n",
      "[40]\ttraining's binary_logloss: 0.236348\tvalid_1's binary_logloss: 0.246155\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.240451\tvalid_1's binary_logloss: 0.245925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:08:20,145] Finished trial#4 resulted in value: 0.7510513425169622. Current best value is 0.7484117954775711 with parameters: {'max_depth': 18, 'num_leaves': 62, 'min_data_in_leaf': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246565\tvalid_1's binary_logloss: 0.250417\n",
      "[20]\ttraining's binary_logloss: 0.239303\tvalid_1's binary_logloss: 0.247433\n",
      "[30]\ttraining's binary_logloss: 0.234012\tvalid_1's binary_logloss: 0.246512\n",
      "[40]\ttraining's binary_logloss: 0.229699\tvalid_1's binary_logloss: 0.246677\n",
      "[50]\ttraining's binary_logloss: 0.225523\tvalid_1's binary_logloss: 0.246928\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's binary_logloss: 0.234012\tvalid_1's binary_logloss: 0.246512\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246266\tvalid_1's binary_logloss: 0.251891\n",
      "[20]\ttraining's binary_logloss: 0.238819\tvalid_1's binary_logloss: 0.249188\n",
      "[30]\ttraining's binary_logloss: 0.233624\tvalid_1's binary_logloss: 0.248845\n",
      "[40]\ttraining's binary_logloss: 0.228932\tvalid_1's binary_logloss: 0.249196\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.236032\tvalid_1's binary_logloss: 0.248647\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246644\tvalid_1's binary_logloss: 0.249902\n",
      "[20]\ttraining's binary_logloss: 0.239191\tvalid_1's binary_logloss: 0.247593\n",
      "[30]\ttraining's binary_logloss: 0.234128\tvalid_1's binary_logloss: 0.247135\n",
      "[40]\ttraining's binary_logloss: 0.229678\tvalid_1's binary_logloss: 0.247469\n",
      "[50]\ttraining's binary_logloss: 0.225496\tvalid_1's binary_logloss: 0.247947\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.233629\tvalid_1's binary_logloss: 0.247115\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.24471\tvalid_1's binary_logloss: 0.257466\n",
      "[20]\ttraining's binary_logloss: 0.237439\tvalid_1's binary_logloss: 0.255245\n",
      "[30]\ttraining's binary_logloss: 0.232296\tvalid_1's binary_logloss: 0.255001\n",
      "[40]\ttraining's binary_logloss: 0.227767\tvalid_1's binary_logloss: 0.25515\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.233717\tvalid_1's binary_logloss: 0.254694\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247064\tvalid_1's binary_logloss: 0.248523\n",
      "[20]\ttraining's binary_logloss: 0.239645\tvalid_1's binary_logloss: 0.246242\n",
      "[30]\ttraining's binary_logloss: 0.234402\tvalid_1's binary_logloss: 0.245929\n",
      "[40]\ttraining's binary_logloss: 0.230109\tvalid_1's binary_logloss: 0.246328\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.234843\tvalid_1's binary_logloss: 0.245882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:08:30,163] Finished trial#5 resulted in value: 0.7508757484115016. Current best value is 0.7484117954775711 with parameters: {'max_depth': 18, 'num_leaves': 62, 'min_data_in_leaf': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245582\tvalid_1's binary_logloss: 0.250396\n",
      "[20]\ttraining's binary_logloss: 0.237179\tvalid_1's binary_logloss: 0.248148\n",
      "[30]\ttraining's binary_logloss: 0.230686\tvalid_1's binary_logloss: 0.248588\n",
      "[40]\ttraining's binary_logloss: 0.22501\tvalid_1's binary_logloss: 0.249472\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.235095\tvalid_1's binary_logloss: 0.248035\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244943\tvalid_1's binary_logloss: 0.252143\n",
      "[20]\ttraining's binary_logloss: 0.236609\tvalid_1's binary_logloss: 0.25065\n",
      "[30]\ttraining's binary_logloss: 0.230151\tvalid_1's binary_logloss: 0.251376\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's binary_logloss: 0.237227\tvalid_1's binary_logloss: 0.250619\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245681\tvalid_1's binary_logloss: 0.249909\n",
      "[20]\ttraining's binary_logloss: 0.237253\tvalid_1's binary_logloss: 0.24846\n",
      "[30]\ttraining's binary_logloss: 0.230976\tvalid_1's binary_logloss: 0.24856\n",
      "[40]\ttraining's binary_logloss: 0.225684\tvalid_1's binary_logloss: 0.249462\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.233385\tvalid_1's binary_logloss: 0.248241\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.243834\tvalid_1's binary_logloss: 0.257405\n",
      "[20]\ttraining's binary_logloss: 0.235251\tvalid_1's binary_logloss: 0.255573\n",
      "[30]\ttraining's binary_logloss: 0.228812\tvalid_1's binary_logloss: 0.256283\n",
      "[40]\ttraining's binary_logloss: 0.223369\tvalid_1's binary_logloss: 0.256954\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.235251\tvalid_1's binary_logloss: 0.255573\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245816\tvalid_1's binary_logloss: 0.248704\n",
      "[20]\ttraining's binary_logloss: 0.237079\tvalid_1's binary_logloss: 0.24708\n",
      "[30]\ttraining's binary_logloss: 0.230908\tvalid_1's binary_logloss: 0.24778\n",
      "[40]\ttraining's binary_logloss: 0.225363\tvalid_1's binary_logloss: 0.248419\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.236431\tvalid_1's binary_logloss: 0.247069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:08:40,688] Finished trial#6 resulted in value: 0.7475090233918428. Current best value is 0.7475090233918428 with parameters: {'max_depth': 18, 'num_leaves': 68, 'min_data_in_leaf': 6}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247108\tvalid_1's binary_logloss: 0.250568\n",
      "[20]\ttraining's binary_logloss: 0.240114\tvalid_1's binary_logloss: 0.247985\n",
      "[30]\ttraining's binary_logloss: 0.23489\tvalid_1's binary_logloss: 0.247833\n",
      "[40]\ttraining's binary_logloss: 0.230178\tvalid_1's binary_logloss: 0.249281\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.236303\tvalid_1's binary_logloss: 0.247791\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246731\tvalid_1's binary_logloss: 0.25209\n",
      "[20]\ttraining's binary_logloss: 0.239418\tvalid_1's binary_logloss: 0.250047\n",
      "[30]\ttraining's binary_logloss: 0.234179\tvalid_1's binary_logloss: 0.249859\n",
      "[40]\ttraining's binary_logloss: 0.229612\tvalid_1's binary_logloss: 0.251551\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.235663\tvalid_1's binary_logloss: 0.249636\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247231\tvalid_1's binary_logloss: 0.250201\n",
      "[20]\ttraining's binary_logloss: 0.240238\tvalid_1's binary_logloss: 0.247856\n",
      "[30]\ttraining's binary_logloss: 0.235186\tvalid_1's binary_logloss: 0.248081\n",
      "[40]\ttraining's binary_logloss: 0.230739\tvalid_1's binary_logloss: 0.249122\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.237579\tvalid_1's binary_logloss: 0.247636\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245508\tvalid_1's binary_logloss: 0.257427\n",
      "[20]\ttraining's binary_logloss: 0.238509\tvalid_1's binary_logloss: 0.25553\n",
      "[30]\ttraining's binary_logloss: 0.233455\tvalid_1's binary_logloss: 0.255858\n",
      "[40]\ttraining's binary_logloss: 0.22905\tvalid_1's binary_logloss: 0.256711\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.237925\tvalid_1's binary_logloss: 0.255457\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247674\tvalid_1's binary_logloss: 0.248442\n",
      "[20]\ttraining's binary_logloss: 0.240416\tvalid_1's binary_logloss: 0.246466\n",
      "[30]\ttraining's binary_logloss: 0.235406\tvalid_1's binary_logloss: 0.246523\n",
      "[40]\ttraining's binary_logloss: 0.231016\tvalid_1's binary_logloss: 0.247859\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.237738\tvalid_1's binary_logloss: 0.24631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:08:51,636] Finished trial#7 resulted in value: 0.7500221738268937. Current best value is 0.7475090233918428 with parameters: {'max_depth': 18, 'num_leaves': 68, 'min_data_in_leaf': 6}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247724\tvalid_1's binary_logloss: 0.250296\n",
      "[20]\ttraining's binary_logloss: 0.241137\tvalid_1's binary_logloss: 0.246946\n",
      "[30]\ttraining's binary_logloss: 0.236952\tvalid_1's binary_logloss: 0.246394\n",
      "[40]\ttraining's binary_logloss: 0.23359\tvalid_1's binary_logloss: 0.246171\n",
      "[50]\ttraining's binary_logloss: 0.230259\tvalid_1's binary_logloss: 0.24643\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.233915\tvalid_1's binary_logloss: 0.246169\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247212\tvalid_1's binary_logloss: 0.252087\n",
      "[20]\ttraining's binary_logloss: 0.240805\tvalid_1's binary_logloss: 0.249471\n",
      "[30]\ttraining's binary_logloss: 0.236323\tvalid_1's binary_logloss: 0.248713\n",
      "[40]\ttraining's binary_logloss: 0.232911\tvalid_1's binary_logloss: 0.248716\n",
      "[50]\ttraining's binary_logloss: 0.229674\tvalid_1's binary_logloss: 0.248968\n",
      "[60]\ttraining's binary_logloss: 0.226671\tvalid_1's binary_logloss: 0.249201\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.232573\tvalid_1's binary_logloss: 0.248706\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247754\tvalid_1's binary_logloss: 0.250311\n",
      "[20]\ttraining's binary_logloss: 0.241212\tvalid_1's binary_logloss: 0.247535\n",
      "[30]\ttraining's binary_logloss: 0.237099\tvalid_1's binary_logloss: 0.247192\n",
      "[40]\ttraining's binary_logloss: 0.233468\tvalid_1's binary_logloss: 0.246875\n",
      "[50]\ttraining's binary_logloss: 0.230133\tvalid_1's binary_logloss: 0.247122\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.233814\tvalid_1's binary_logloss: 0.246867\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245808\tvalid_1's binary_logloss: 0.257338\n",
      "[20]\ttraining's binary_logloss: 0.239509\tvalid_1's binary_logloss: 0.254762\n",
      "[30]\ttraining's binary_logloss: 0.235241\tvalid_1's binary_logloss: 0.254296\n",
      "[40]\ttraining's binary_logloss: 0.231484\tvalid_1's binary_logloss: 0.254409\n",
      "[50]\ttraining's binary_logloss: 0.2284\tvalid_1's binary_logloss: 0.25465\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's binary_logloss: 0.233968\tvalid_1's binary_logloss: 0.254221\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.248074\tvalid_1's binary_logloss: 0.248853\n",
      "[20]\ttraining's binary_logloss: 0.24142\tvalid_1's binary_logloss: 0.246628\n",
      "[30]\ttraining's binary_logloss: 0.237101\tvalid_1's binary_logloss: 0.246222\n",
      "[40]\ttraining's binary_logloss: 0.233457\tvalid_1's binary_logloss: 0.246359\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.238241\tvalid_1's binary_logloss: 0.246164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:09:04,933] Finished trial#8 resulted in value: 0.7509102748773351. Current best value is 0.7475090233918428 with parameters: {'max_depth': 18, 'num_leaves': 68, 'min_data_in_leaf': 6}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246733\tvalid_1's binary_logloss: 0.250363\n",
      "[20]\ttraining's binary_logloss: 0.239789\tvalid_1's binary_logloss: 0.247529\n",
      "[30]\ttraining's binary_logloss: 0.235004\tvalid_1's binary_logloss: 0.246804\n",
      "[40]\ttraining's binary_logloss: 0.230934\tvalid_1's binary_logloss: 0.247157\n",
      "[50]\ttraining's binary_logloss: 0.226943\tvalid_1's binary_logloss: 0.247271\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.234608\tvalid_1's binary_logloss: 0.246781\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246399\tvalid_1's binary_logloss: 0.251976\n",
      "[20]\ttraining's binary_logloss: 0.239461\tvalid_1's binary_logloss: 0.249308\n",
      "[30]\ttraining's binary_logloss: 0.234593\tvalid_1's binary_logloss: 0.248651\n",
      "[40]\ttraining's binary_logloss: 0.230464\tvalid_1's binary_logloss: 0.248901\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.235347\tvalid_1's binary_logloss: 0.248617\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.246929\tvalid_1's binary_logloss: 0.250027\n",
      "[20]\ttraining's binary_logloss: 0.239902\tvalid_1's binary_logloss: 0.247557\n",
      "[30]\ttraining's binary_logloss: 0.235001\tvalid_1's binary_logloss: 0.24709\n",
      "[40]\ttraining's binary_logloss: 0.230989\tvalid_1's binary_logloss: 0.247346\n",
      "[50]\ttraining's binary_logloss: 0.227326\tvalid_1's binary_logloss: 0.247665\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.234602\tvalid_1's binary_logloss: 0.247089\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245097\tvalid_1's binary_logloss: 0.257319\n",
      "[20]\ttraining's binary_logloss: 0.238115\tvalid_1's binary_logloss: 0.255116\n",
      "[30]\ttraining's binary_logloss: 0.233243\tvalid_1's binary_logloss: 0.255074\n",
      "[40]\ttraining's binary_logloss: 0.229211\tvalid_1's binary_logloss: 0.25535\n",
      "[50]\ttraining's binary_logloss: 0.225532\tvalid_1's binary_logloss: 0.255984\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.232329\tvalid_1's binary_logloss: 0.254961\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.247232\tvalid_1's binary_logloss: 0.248812\n",
      "[20]\ttraining's binary_logloss: 0.240177\tvalid_1's binary_logloss: 0.246376\n",
      "[30]\ttraining's binary_logloss: 0.235297\tvalid_1's binary_logloss: 0.246256\n",
      "[40]\ttraining's binary_logloss: 0.230957\tvalid_1's binary_logloss: 0.246582\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.237478\tvalid_1's binary_logloss: 0.246044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:09:26,284] Finished trial#9 resulted in value: 0.750112300424667. Current best value is 0.7475090233918428 with parameters: {'max_depth': 18, 'num_leaves': 68, 'min_data_in_leaf': 6}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244094\tvalid_1's binary_logloss: 0.250524\n",
      "[20]\ttraining's binary_logloss: 0.23454\tvalid_1's binary_logloss: 0.249368\n",
      "[30]\ttraining's binary_logloss: 0.227144\tvalid_1's binary_logloss: 0.249835\n",
      "[40]\ttraining's binary_logloss: 0.220757\tvalid_1's binary_logloss: 0.253144\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.23454\tvalid_1's binary_logloss: 0.249368\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.243597\tvalid_1's binary_logloss: 0.252075\n",
      "[20]\ttraining's binary_logloss: 0.234148\tvalid_1's binary_logloss: 0.25098\n",
      "[30]\ttraining's binary_logloss: 0.226404\tvalid_1's binary_logloss: 0.252708\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.236663\tvalid_1's binary_logloss: 0.25078\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244229\tvalid_1's binary_logloss: 0.250446\n",
      "[20]\ttraining's binary_logloss: 0.234706\tvalid_1's binary_logloss: 0.249871\n",
      "[30]\ttraining's binary_logloss: 0.227067\tvalid_1's binary_logloss: 0.25116\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.237226\tvalid_1's binary_logloss: 0.249356\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.242434\tvalid_1's binary_logloss: 0.257533\n",
      "[20]\ttraining's binary_logloss: 0.232971\tvalid_1's binary_logloss: 0.256395\n",
      "[30]\ttraining's binary_logloss: 0.225353\tvalid_1's binary_logloss: 0.258563\n",
      "[40]\ttraining's binary_logloss: 0.219374\tvalid_1's binary_logloss: 0.261571\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.232971\tvalid_1's binary_logloss: 0.256395\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244607\tvalid_1's binary_logloss: 0.248949\n",
      "[20]\ttraining's binary_logloss: 0.234883\tvalid_1's binary_logloss: 0.248618\n",
      "[30]\ttraining's binary_logloss: 0.227509\tvalid_1's binary_logloss: 0.250691\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.238288\tvalid_1's binary_logloss: 0.248273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:09:47,563] Finished trial#10 resulted in value: 0.746959385927514. Current best value is 0.746959385927514 with parameters: {'max_depth': 20, 'num_leaves': 80, 'min_data_in_leaf': 3}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244094\tvalid_1's binary_logloss: 0.250524\n",
      "[20]\ttraining's binary_logloss: 0.23454\tvalid_1's binary_logloss: 0.249368\n",
      "[30]\ttraining's binary_logloss: 0.227144\tvalid_1's binary_logloss: 0.249835\n",
      "[40]\ttraining's binary_logloss: 0.220757\tvalid_1's binary_logloss: 0.253144\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.23454\tvalid_1's binary_logloss: 0.249368\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.243597\tvalid_1's binary_logloss: 0.252075\n",
      "[20]\ttraining's binary_logloss: 0.234148\tvalid_1's binary_logloss: 0.25098\n",
      "[30]\ttraining's binary_logloss: 0.226404\tvalid_1's binary_logloss: 0.252708\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.236663\tvalid_1's binary_logloss: 0.25078\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244229\tvalid_1's binary_logloss: 0.250446\n",
      "[20]\ttraining's binary_logloss: 0.234706\tvalid_1's binary_logloss: 0.249871\n",
      "[30]\ttraining's binary_logloss: 0.227067\tvalid_1's binary_logloss: 0.25116\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.237226\tvalid_1's binary_logloss: 0.249356\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.242434\tvalid_1's binary_logloss: 0.257533\n",
      "[20]\ttraining's binary_logloss: 0.232971\tvalid_1's binary_logloss: 0.256395\n",
      "[30]\ttraining's binary_logloss: 0.225353\tvalid_1's binary_logloss: 0.258563\n",
      "[40]\ttraining's binary_logloss: 0.219374\tvalid_1's binary_logloss: 0.261571\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.232971\tvalid_1's binary_logloss: 0.256395\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244607\tvalid_1's binary_logloss: 0.248949\n",
      "[20]\ttraining's binary_logloss: 0.234883\tvalid_1's binary_logloss: 0.248618\n",
      "[30]\ttraining's binary_logloss: 0.227509\tvalid_1's binary_logloss: 0.250691\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.238288\tvalid_1's binary_logloss: 0.248273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:10:05,448] Finished trial#11 resulted in value: 0.746959385927514. Current best value is 0.746959385927514 with parameters: {'max_depth': 20, 'num_leaves': 80, 'min_data_in_leaf': 3}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.2445\tvalid_1's binary_logloss: 0.250845\n",
      "[20]\ttraining's binary_logloss: 0.235255\tvalid_1's binary_logloss: 0.249121\n",
      "[30]\ttraining's binary_logloss: 0.227912\tvalid_1's binary_logloss: 0.25022\n",
      "[40]\ttraining's binary_logloss: 0.221791\tvalid_1's binary_logloss: 0.251932\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.234498\tvalid_1's binary_logloss: 0.249016\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244019\tvalid_1's binary_logloss: 0.251846\n",
      "[20]\ttraining's binary_logloss: 0.234987\tvalid_1's binary_logloss: 0.250728\n",
      "[30]\ttraining's binary_logloss: 0.227674\tvalid_1's binary_logloss: 0.252851\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.236569\tvalid_1's binary_logloss: 0.250533\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244625\tvalid_1's binary_logloss: 0.250614\n",
      "[20]\ttraining's binary_logloss: 0.235245\tvalid_1's binary_logloss: 0.249921\n",
      "[30]\ttraining's binary_logloss: 0.228062\tvalid_1's binary_logloss: 0.251218\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.237762\tvalid_1's binary_logloss: 0.249327\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.242853\tvalid_1's binary_logloss: 0.257728\n",
      "[20]\ttraining's binary_logloss: 0.233841\tvalid_1's binary_logloss: 0.256672\n",
      "[30]\ttraining's binary_logloss: 0.22669\tvalid_1's binary_logloss: 0.257659\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.237892\tvalid_1's binary_logloss: 0.25661\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.245043\tvalid_1's binary_logloss: 0.248613\n",
      "[20]\ttraining's binary_logloss: 0.235587\tvalid_1's binary_logloss: 0.247313\n",
      "[30]\ttraining's binary_logloss: 0.228171\tvalid_1's binary_logloss: 0.24894\n",
      "[40]\ttraining's binary_logloss: 0.222033\tvalid_1's binary_logloss: 0.250815\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.235587\tvalid_1's binary_logloss: 0.247313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:10:23,445] Finished trial#12 resulted in value: 0.7472820985160596. Current best value is 0.746959385927514 with parameters: {'max_depth': 20, 'num_leaves': 80, 'min_data_in_leaf': 3}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244094\tvalid_1's binary_logloss: 0.250524\n",
      "[20]\ttraining's binary_logloss: 0.23454\tvalid_1's binary_logloss: 0.249368\n",
      "[30]\ttraining's binary_logloss: 0.227144\tvalid_1's binary_logloss: 0.249835\n",
      "[40]\ttraining's binary_logloss: 0.220757\tvalid_1's binary_logloss: 0.253144\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.23454\tvalid_1's binary_logloss: 0.249368\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.243597\tvalid_1's binary_logloss: 0.252075\n",
      "[20]\ttraining's binary_logloss: 0.234148\tvalid_1's binary_logloss: 0.25098\n",
      "[30]\ttraining's binary_logloss: 0.226404\tvalid_1's binary_logloss: 0.252708\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.236663\tvalid_1's binary_logloss: 0.25078\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244229\tvalid_1's binary_logloss: 0.250446\n",
      "[20]\ttraining's binary_logloss: 0.234706\tvalid_1's binary_logloss: 0.249871\n",
      "[30]\ttraining's binary_logloss: 0.227067\tvalid_1's binary_logloss: 0.25116\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.237226\tvalid_1's binary_logloss: 0.249356\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.242434\tvalid_1's binary_logloss: 0.257533\n",
      "[20]\ttraining's binary_logloss: 0.232971\tvalid_1's binary_logloss: 0.256395\n",
      "[30]\ttraining's binary_logloss: 0.225353\tvalid_1's binary_logloss: 0.258563\n",
      "[40]\ttraining's binary_logloss: 0.219374\tvalid_1's binary_logloss: 0.261571\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.232971\tvalid_1's binary_logloss: 0.256395\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.244607\tvalid_1's binary_logloss: 0.248949\n",
      "[20]\ttraining's binary_logloss: 0.234883\tvalid_1's binary_logloss: 0.248618\n",
      "[30]\ttraining's binary_logloss: 0.227509\tvalid_1's binary_logloss: 0.250691\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.238288\tvalid_1's binary_logloss: 0.248273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-11 18:10:37,845] Finished trial#13 resulted in value: 0.746959385927514. Current best value is 0.746959385927514 with parameters: {'max_depth': 20, 'num_leaves': 80, 'min_data_in_leaf': 3}.\n"
     ]
    }
   ],
   "source": [
    "# optuna でハイパーパラメータの最適化\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=30, timeout=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'num_leaves': 80, 'min_data_in_leaf': 3}\n",
      "0.746959385927514\n"
     ]
    }
   ],
   "source": [
    "# optuna が見つけてくれた結果を確認\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ＜考察＞  \n",
    "## 今回のoptunaによる結果では、max_depthとnum_leavesがサーチ範囲の最大値となった。このことは、LGBMとOptunaのいずれの性質に依るものであるのかは不明だが、評価値が向上するわけでもなく過学習の懸念もあるため、グリッドサーチによるハイパーパラメータを採用してkaggleにsubmitする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】最終的なモデルの選定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "### テスト用のデータを、トレイン用データと同様に加工する ###\n",
    "\n",
    "df = pd.read_csv('application_test.csv')#教師データを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_object = df.select_dtypes(include = \"object\")\n",
    "for column in df_object.columns:\n",
    "    df[column] = df_object[column].fillna(df_object[column].mode()[0])\n",
    "df_int_float = df.select_dtypes(exclude = \"object\")\n",
    "for column in df_int_float.columns:\n",
    "    df[column] = df_int_float[column].fillna(df_int_float[column].mean())\n",
    "    \n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48744, 121)\n",
      "(48744, 258)\n",
      "(48744, 242)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df_onehot = df\n",
    "for column in df_object.columns:\n",
    "    df_onehot = pd.concat([df_onehot, pd.get_dummies(df[column])],axis=1)\n",
    "\n",
    "print(df_onehot.shape)\n",
    "for column in df_object.columns:\n",
    "    df_onehot = df_onehot.drop(column, axis=1)\n",
    "\n",
    "print(df_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "###　特徴量選択　###\n",
    "df_onehot=df_onehot[['LIVINGAREA_MODE', 'Secondary / secondary special',\n",
    "       'YEARS_BEGINEXPLUATATION_MODE', 'COMMONAREA_MODE', 'TOTALAREA_MODE',\n",
    "       'M', 'OWN_CAR_AGE', 'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "       'HOUR_APPR_PROCESS_START', 'AMT_GOODS_PRICE', 'AMT_CREDIT',\n",
    "       'REGION_POPULATION_RELATIVE', 'AMT_INCOME_TOTAL',\n",
    "       'DAYS_LAST_PHONE_CHANGE', 'DAYS_EMPLOYED', 'AMT_ANNUITY',\n",
    "       'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'DAYS_BIRTH', 'EXT_SOURCE_1',\n",
    "       'EXT_SOURCE_2', 'EXT_SOURCE_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 特徴量の追加 ###\n",
    "df_onehot[\"CREDIT/INCOME\"] = df_onehot[\"AMT_CREDIT\"]/df_onehot[\"AMT_INCOME_TOTAL\"]\n",
    "df_onehot[\"CREDIT/GOODS\"] = df_onehot[\"AMT_CREDIT\"]/df_onehot[\"AMT_GOODS_PRICE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC:0.7620590256555341\n",
      "0.06774245537680888\n",
      "ROC_AUC:0.751086759594842\n",
      "0.06823454340040781\n",
      "ROC_AUC:0.7515583977112923\n",
      "0.06749399722408442\n",
      "ROC_AUC:0.7503580090332171\n",
      "0.07003134692012211\n",
      "ROC_AUC:0.7512002843021052\n",
      "0.0672356991024321\n",
      "ROC_AUC:[0.7620590256555341, 0.751086759594842, 0.7515583977112923, 0.7503580090332171, 0.7512002843021052]\n"
     ]
    }
   ],
   "source": [
    "### LGBMによる学習済みモデル作成 ###\n",
    "\n",
    "params = {'max_depth':8,            \n",
    "          \"min_data_in_leaf\":15,\n",
    "          \"num_leaves\": 45\n",
    "         }\n",
    "\n",
    "scores = []\n",
    "for t_index, v_index in kf.split(X):\n",
    "    X_train, y_train = X[t_index], y[t_index]\n",
    "    X_eval, y_eval = X[v_index],y[v_index]\n",
    "    \n",
    "    train_data = lgbm.Dataset(X_train, y_train)\n",
    "    eval_data = lgbm.Dataset(X_eval, y_eval)\n",
    "    \n",
    "    clf_sub = lgbm.train(params=params,\n",
    "                      train_set=train_data,\n",
    "                      valid_sets=[train_data, eval_data],\n",
    "                      verbose_eval=10)\n",
    "\n",
    "    y_pred = clf_sub.predict(X_eval)\n",
    "    mse_score = mean_squared_error(y_eval, y_pred)\n",
    "    print(\"ROC_AUC:{}\".format(roc_auc_score(y_eval, y_pred)))\n",
    "    scores.append(roc_auc_score(y_eval, y_pred))                             # 評価値を平均化するため,リストに追加していく\n",
    "    print(mse_score)\n",
    "\n",
    "print(\"ROC_AUC:{}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7512108219955544"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_eval, np.abs(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7512006182558763"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[np.where(y_pred<0)]=0\n",
    "roc_auc_score(y_eval, np.abs(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　学習済みモデルに、テストデータを入れて推論\n",
    "y_pred_sub = clf_sub.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# y_pred_subに負の値が含まれていてsubmitできなかったので、推論結果を絶対値に変換してsubmit\n",
    "sub['TARGET'] = np.abs(y_pred_sub)\n",
    "sub.to_csv('submission_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAGGLEのスコアは0.73345となった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# y_pred_subに負の値が含まれていてsubmitできなかったので、負のサンプルをゼロに変換してsubmit\n",
    "y_pred_sub[np.where(y_pred_sub < 0)] = 0\n",
    "sub['TARGET'] = y_pred_sub\n",
    "sub.to_csv('submission_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAGGLEのスコアは同様に0.73345となった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMModel(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "          importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "          min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "          n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "          random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "          subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## メモ　https://lightgbm.readthedocs.io/en/latest/Python-API.html#scikit-learn-api\n",
    "lgbm.LGBMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.LGBMRegressor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sprint21 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "pd.set_option('display.max_columns', 250)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    def __init__(self, X, y, batch_size = 1, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】SimpleRNNのフォワードプロパゲーション実装  \n",
    "## 【問題2】小さな配列でのフォワードプロパゲーションの実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    def forward(self,x):\n",
    "#          out = 1/(1 + np.exp(-x))\n",
    "        out = (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    def backward(self,dout):\n",
    "        dx = dout * (1 - self.out**2) ### 確認。out?\n",
    "#         dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        layer.W = layer.W - self.lr * layer.dW\n",
    "        layer.B = layer.B - self.lr * layer.dB.mean(axis = 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def WI(self, n_nodes1, n_nodes2):\n",
    "        WI = np.random.randn(n_nodes1, n_nodes2) * self.sigma\n",
    "        return WI\n",
    "    def BI(self, n_nodes2):\n",
    "        BI = np.random.randn(n_nodes2) * self.sigma\n",
    "        return BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_layer:\n",
    "\n",
    "    def __init__(self,batch_size, n_sequence, n_features, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.initializer = initializer\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.n_sequence = n_sequence\n",
    "        self.n_nodes = 4\n",
    "        self.n_features = n_features\n",
    "\n",
    "        self.Wx = np.zeros([self.n_features, self.n_nodes])\n",
    "        self.Wh = np.zeros([self.n_nodes, self.n_nodes])\n",
    "        self.B =  np.zeros(self.n_nodes)\n",
    "        \n",
    "    def forward(self, Z, H):\n",
    "        self.Z = Z\n",
    "        self.H = H\n",
    "        self.activation1=Tanh()\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            for j in range(self.n_sequence):\n",
    "                A = np.dot(self.Z[i][j], self.Wx) + np.dot(self.H, self.Wh)+ self.B\n",
    "                self.H = self.activation1.forward(A)\n",
    "        return self.H\n",
    "  \n",
    "#     def backward(self, dA):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ｄｉｖｅｒの値と一致した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79494228, 0.81839002, 0.83939649, 0.85584174])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
    "\n",
    "R1 = RNN_layer(1,3,2,SimpleInitializer,SGD)\n",
    "\n",
    "R1.Wx = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
    "R1.Wh= np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
    "R1.B = np.array([1,1,1,1])\n",
    "\n",
    "R1.forward(x, np.array([0,0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】（アドバンス課題）バックプロパゲーションの実装（省略）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
